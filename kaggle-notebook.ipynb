{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:03:24.051586Z","iopub.status.busy":"2024-06-28T12:03:24.051156Z","iopub.status.idle":"2024-06-28T12:03:31.354884Z","shell.execute_reply":"2024-06-28T12:03:31.354005Z","shell.execute_reply.started":"2024-06-28T12:03:24.051550Z"},"trusted":true},"outputs":[],"source":["#basics\n","import os\n","import time\n","import json\n","import pickle\n","import openeo\n","import numpy as np\n","\n","# geography\n","import geopandas as gpd\n","import rasterio\n","from rasterio.features import geometry_mask\n","\n","\n","#download\n","import pyrosm as pyr\n","from openeo.rest import OpenEoApiError\n","from openeo.processes import ProcessBuilder, if_, is_nan\n","\n","\n","\n","# plotting \n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","import logging\n","from pyrosm.data import sources\n","import numpy as np\n","\n","\n","\n","import rasterio\n","import numpy as np\n","import torch\n","from torch.utils.data import random_split, DataLoader, Dataset\n","import matplotlib.pyplot as plt\n","from scipy.special import kl_div\n","import pandas as pd\n","import logging\n","\n","def setup_logger(level: int = logging.INFO):\n","    \"\"\"\n","    Set up a logger for the pipeline. \n","    \"\"\"\n","    logger = logging.getLogger()\n","    formatter = logging.Formatter(\n","        \"%(asctime)s - %(name)s - %(levelname)s - %(funcName)s - %(message)s\"\n","    )\n","    \n","    console_handler = logging.StreamHandler()\n","    console_handler.setFormatter(formatter)\n","    \n","    file_handler = logging.FileHandler(\"main.log\")\n","    file_handler.setFormatter(formatter)\n","\n","    logger.setLevel(level)\n","    logger.addHandler(console_handler)\n","    logger.addHandler(file_handler)\n","\n","    return logger\n","\n","\n","def get_available_cities():\n","    \"\"\"\n","    Return all available cities from pyrosm \n","    \"\"\"\n","    return sources.cities.available\n","\n","\n","def stretch_hist(band):\n","    \"\"\"\n","    Apply histogram stretching\"\"\"\n","    p2, p98 = np.percentile(band, (0.5, 99.5))\n","    return np.clip((band - p2) * 255.0 / (p98 - p2), 0, 255).astype(np.uint8)\n","\n","\n","class DataHandler: \n","    def __init__(self, logger):\n","        \"\"\"\n","        Initialize the DataHandler class and define openeo params.\n","        \"\"\"\n","        self.logger = logger\n","        self.openeo_temporal_extent = [\"2023-05-01\", \"2023-09-30\"]\n","        self.openeo_bands = [\"B04\", \"B03\", \"B02\", \"B08\", \"B12\", \"B11\", \"SCL\"]\n","        self.openeo_max_cloud_cover = 30\n","        self.openeo_spatial_resolution = 10\n","        self.openeo_connection = None\n","        self.openeo_collections = None\n","        self.openeo_jobs = None\n","        \n","        if not os.path.exists(\"data\"):\n","            os.makedirs(\"data\")\n","            logger.info(\"Created data directory\")\n","        else:\n","            logger.info(\"Data directory already exists\")\n","\n","\n","    def create_directory(self, city: str):\n","        \"\"\"\n","        Create a directory for each city.\n","        \"\"\"\n","        os.makedirs(f\"data/{city}\", exist_ok=True)\n","        self.logger.info(f\"{city}: Directory available\")\n","\n","\n","    def get_buildings(self, city: str):\n","        \"\"\"\n","        Return buildings for a given city\n","        \"\"\"\n","        self.create_directory(city)\n","        \n","        # Check if local data for city is available\n","        if \"buildings.geojson\" in os.listdir(f\"data/{city}\"):\n","            self.logger.info(f\"{city}: Using local building data\")\n","            return gpd.read_file(f\"data/{city}/buildings.geojson\")\n","\n","        # Download data for city\n","        fp = pyr.get_data(city, directory=os.path.join(\"data\", city))\n","        osm = pyr.OSM(fp)\n","        self.logger.info(f\"{city}: Downloaded data to data/{city}\")\n","\n","        # Get bounding box for city\n","        boundingbox = self.get_boundingbox(city, osm)\n","\n","        # Get the buildings of the city\n","        buildings_geodf = osm.get_buildings()\n","\n","        # Remove buildings outside of the bounding box of the city\n","        buildings_geodf = buildings_geodf.cx[boundingbox[0] : boundingbox[2], boundingbox[1] : boundingbox[3]]\n","\n","        # Save the data of the city\n","        buildings_path = f\"data/{city}/buildings.geojson\"\n","        buildings_geodf.to_file(buildings_path, driver=\"GeoJSON\")\n","        self.logger.info(f\"{city}: Stored data to data/{city}/buildings.geojson\")\n","\n","        return buildings_geodf\n","\n","\n","    def get_boundingbox(self, city: str, osm = None):\n","        \"\"\"\n","        Get the bounding box for a city.\n","        \"\"\"\n","\n","        # Return bounding box for Berlin as specified in exercise sheet to ensure correct testing results\n","        if city == \"Berlin\":\n","            return [13.294333, 52.454927, 13.500205, 52.574409]\n","\n","        # Check if local bounds are available\n","        bounds_path = f\"data/{city}/bounds.pkl\"\n","        if os.path.exists(bounds_path):\n","            with open(bounds_path, \"rb\") as f:\n","                boundingbox = pickle.load(f)\n","            return boundingbox\n","        \n","        # Ensure OSM data is available \n","        if osm is None:\n","            self.get_buildings(city=city)\n","\n","        # Get the boundaries\n","        geoframe_bounds = osm.get_boundaries()\n","        boundingbox = geoframe_bounds[geoframe_bounds[\"name\"] == city].total_bounds\n","\n","        # Check if bounding box is None\n","        if np.isnan(boundingbox[0]) or np.isnan(boundingbox[1]) or np.isnan(boundingbox[2]) or np.isnan(boundingbox[3]):\n","            self.logger.info(f\"{city}: Bounding box is None. Using total bounds instead\")\n","            boundingbox = geoframe_bounds.total_bounds\n","        self.logger.info(f\"{city}: Bounding box is {boundingbox}\")     \n","\n","        # Save total bounds to pickle file\n","        with open(bounds_path, \"wb\") as f:\n","            pickle.dump(boundingbox, f)\n","        self.logger.info(f\"{city}: Saved bounds to data/{city}/bounds.pkl\")\n","\n","        return boundingbox\n","    \n","\n","    def get_satellite_image(self, city: str, return_rasterio_dataset = False): \n","        \"\"\"\n","        Get satellite images for a city. Use local data if available. Returns an Array with (H, W, C) shape\n","        \"\"\"\n","        if os.path.exists(f\"data/{city}/openEO.tif\"):\n","            self.logger.info(f\"{city}: Using local satellite image\")\n","            ds = rasterio.open(f\"data/{city}/openEO.tif\")\n","            if return_rasterio_dataset:\n","                return ds\n","            \n","            # Read all channels\n","            sat_data = ds.read()\n","\n","            # Transpose to (H, W, C)\n","            sat_data = np.transpose(sat_data, (1, 2, 0))\n","            return sat_data\n","        else:\n","            self.download_satellite_image(city)\n","            return self.get_satellite_image(city)\n","    \n","\n","    def connect_to_openeo(self):\n","        \"\"\"\n","        Connect to the openEO backend and \n","        \"\"\"\n","        if self.openeo_connection is None:\n","            connection = openeo.connect(\"openeo.dataspace.copernicus.eu\")\n","            connection.authenticate_oidc()\n","            self.openeo_connection = connection\n","\n","            self.logger.info(\"Connected to openEO\")\n","        else:\n","            self.logger.info(\"Already connected to openEO\")\n","\n","\n","    def download_satellite_image(self, city: str):\n","        \"\"\"\n","        Download satellite images for a city. Retry for 3 times if the job fails or takes longer than 30 min per job.\n","        \"\"\"\n","        self.connect_to_openeo()\n","        \n","        # Log the currently running jobs\n","        self.logger.info(\"Current jobs:\")\n","        for idx, job in enumerate(self.openeo_connection.list_jobs()):\n","            self.logger.info(f\"{idx} {job['id']} {job['status']}\")\n","\n","        # Retry job up to 3 times. Raise exception after 3 retries.\n","        job_finished = False\n","        job_number_of_retries = 0\n","        while not job_finished : \n","            if job_number_of_retries > 3:\n","                self.logger.error(f\"{city}: Job failed after 3 retries\")\n","                raise Exception(f\"{city}: Job failed after 3 retries\")\n","            job = self.create_and_start_openeo_job(city)    \n","            job_finished = self.await_job(city, job)\n","            job_number_of_retries += 1\n","\n","        # Get job results and store in data/city\n","        job_results = self.openeo_connection.job(job.job_id).get_results()\n","        job_results.download_files(f\"data/{city}\")\n","        self.logger.info(f\"{city}: Downloaded job results to data/{city}\")\n","\n","\n","    def delete_jobs(self):\n","        \"\"\"\n","        Delete all jobs on the openEO backend. Use only for debugging. \n","        \"\"\"\n","        self.connect_to_openeo()\n","\n","        for idx, job in enumerate(self.openeo_connection.list_jobs()):\n","            self.logger.info(f\"Deleting job {idx}, {job['id']}, {job['status']}\")\n","            self.openeo_connection.job(job[\"id\"]).delete_job()\n","\n","\n","    def create_and_start_openeo_job(self, city: str, collection_id: str = \"SENTINEL2_L2A\"):\n","        \"\"\"\n","        Creates an openeo processing job for a city and starts it.\n","        \"\"\"\n","        # Transform order in boundingbox to dict\n","        boundingbox = self.get_boundingbox(city)\n","        boundingbox = {\"west\": boundingbox[0], \"south\": boundingbox[1], \"east\": boundingbox[2], \"north\": boundingbox[3]}\n","        \n","        # Create datacube\n","        datacube = self.openeo_connection.load_collection(\n","            collection_id=collection_id,\n","            spatial_extent=boundingbox,\n","            temporal_extent=self.openeo_temporal_extent,\n","            bands=self.openeo_bands,\n","            max_cloud_cover=self.openeo_max_cloud_cover,\n","        ).resample_spatial(self.openeo_spatial_resolution)\n","\n","        # Create cloud mask\n","        scl = datacube.band(\"SCL\")\n","\n","        # Filter out cloud median probability, cloud high probability, and snow/ice\n","        mask = (scl == 8) | (scl == 9) | (scl == 11)\n","\n","        # Resample mask to the spatial resolution of the datacube\n","        mask = mask.resample_cube_spatial(datacube.band(\"B04\"))\n","        \n","        # Create the RGB image\n","        datacube_rgbFU = datacube.filter_bands(self.openeo_bands[:-1])\n","        \n","        # Apply cloud mask\n","        datacube_rgb_masked = datacube_rgbFU.mask(mask)\n","        \n","        # Reduce temporal to median \n","        datacube_rgb_masked_reduced_t = datacube_rgb_masked.reduce_temporal(\"median\")\n","\n","        # Define image format \n","        datacube_for_submission = datacube_rgb_masked_reduced_t.save_result(format=\"GTiff\")\n","        \n","        # Create openEO job with datacube\n","        job = datacube_for_submission.create_job(title=f\"{city}__pic\")\n","        self.logger.info(f\"{city}: Created openEO job\")\n","\n","        # Start openEO job\n","        job.start_job()\n","        self.logger.info(f\"{city}: Started openEO job with ID: {job.job_id}\")        \n","\n","        return job\n","\n","\n","    def await_job(self, city, job):\n","        \"\"\"\n","        Awaits the processing of a openeo job. \n","        Returns when the job is finished or raises an exception if the job failed.\n","        \"\"\"\n","\n","        for i in range(30):\n","            status = self.openeo_connection.job(job.job_id).status()\n","            self.logger.debug(f\"{city}: Job {job.job_id} status: {status}\")\n","          \n","            if status == \"finished\":\n","                self.logger.info(f\"{city}: Job {job.job_id} finished\")\n","                return True\n","            \n","            elif status == \"error\":\n","                self.logger.warning(f\"{city}: Job {job.job_id} failed. Trying again.\")\n","                return False            \n","            \n","            time.sleep(60)\n","        self.logger.error(f\"{city}: Job {job.job_id} did not finish in time\")\n","        return False\n","\n","    def get_building_mask(self, city: str, loaded_buildings = None, all_touched: bool = False):  \n","        \"\"\"\n","        Get the local building mask for buildings in a city.\n","        \"\"\"\n","        if all_touched:\n","            filename = \"building_mask_dense\"\n","        else:\n","            filename = \"building_mask_sparse\"\n","        # Check if the building mask is already available\n","        if os.path.exists(f\"data/{city}/{filename}.tif\"):\n","            self.logger.info(f\"{city}: Using local building mask\")\n","            return rasterio.open(f\"data/{city}/{filename}.tif\").read(1)\n","\n","        # Create new building mask \n","        satellite_image = self.get_satellite_image(city, return_rasterio_dataset=True)\n","\n","        # Get satellite image metadata\n","        transform = satellite_image.transform\n","        out_shape = (satellite_image.height, satellite_image.width)\n","        crs = satellite_image.crs\n","\n","        # Read the GeoJSON file with building polygons\n","        if loaded_buildings is not None:\n","            buildings = loaded_buildings\n","        else:\n","            buildings = self.get_buildings(city)\n","            buildings = buildings.to_crs(crs)  # Ensure the CRS matches the GeoTIFF\n","\n","        # Create a mask where pixels inside buildings are True, others are False\n","        # TODO all_touched paramer nutzen für zweite Maske\n","        mask = geometry_mask(\n","            buildings.geometry, transform=transform, invert=True, out_shape=out_shape, all_touched=all_touched,\n","        )\n","        \n","        # Store the mask as a GeoTIFF file\n","        \n","        out_meta = satellite_image.meta\n","        out_meta.update(\n","            {\n","                \"driver\": \"GTiff\",\n","                \"height\": mask.shape[0],\n","                \"width\": mask.shape[1],\n","                # \"transform\": transform,\n","                \"count\": 1,\n","            }\n","        )\n","\n","        # boolmask is automatically being saved as int16 [0,1]\n","  \n","        with rasterio.open(f\"data/{city}/{filename}.tif\", \"w\", **out_meta) as dest:\n","            dest.write(mask, indexes=1)\n","\n","        return mask\n","\n","\n","\n","    def plot(self, city: str = \"BerlinTest\", \n","\n","             backend: str = \"matplotlib\",\n","             figure_size: tuple = (10, 10),\n","             brightness: int = 5,\n","             image_directory: str = \"img/\",\n","             show_plot: bool = False,\n","             slice_to_be_plotted = None\n","             ):\n","        \"\"\"\n","        Plot the data for a city either with matplotlib or plotly.\n","        \"\"\"\n","\n","    \n","    \n","        if backend != \"plotly\" and backend != \"matplotlib\":            \n","            raise NotImplementedError(\"Only matplotlib and plotly is supported at the moment\")\n","        \n","        satellite_data = self.get_satellite_image(city)        \n","        mask = self.get_building_mask(city)\n","        # Take out slice if only a slice is to be plotted\n","        if slice_to_be_plotted is not None:\n","            satellite_data = satellite_data[slice(*slice_to_be_plotted)]\n","            mask = mask[slice(*slice_to_be_plotted)]\n","        \n","        if backend ==\"matplotlib\":\n","            #load buildings\n","            buildings = self.get_buildings(city)\n","\n","            # create image out path\n","            image_path_out = os.path.join(image_directory, city)\n","             # make the output directory if not exists\n","            os.makedirs(image_path_out, exist_ok=True)\n","\n","            # Design plots\n","            fig, ax = plt.subplots(figsize=figure_size)\n","            buildings.plot(ax=ax, color=\"black\")\n","            plt.title(f\"{city} buildings\")\n","            plt.axis(\"off\")\n","\n","        # RGB Bands from Sentinel 2\n","        red = satellite_data[...,0]\n","        green = satellite_data[...,1]\n","        blue = satellite_data[...,2]\n","\n","        # Apply histogram stretching\n","        red_stretched = stretch_hist(red)\n","        green_stretched = stretch_hist(green)\n","        blue_stretched = stretch_hist(blue)\n","\n","        # Stack the bands after stretching\n","        rgb_stretched = np.dstack((red_stretched, green_stretched, blue_stretched))\n","\n","        \n","\n","        if backend ==\"matplotlib\":\n","            # Plot the histogram-stretched RGB image\n","            plt.figure(figsize=figure_size)\n","            plt.imshow(rgb_stretched)\n","            # plt.title(\"Histogram Stretched RGB Composite Image\")\n","            plt.title(f\"{city} RGB Bands from Sentinel-2 L2A\")\n","            plt.axis(\"off\")\n","            # plt.show()\n","            plt.savefig(os.path.join(image_path_out, f\"{city}_RGB.png\"))\n","            if show_plot:\n","                plt.show()\n","            plt.close()\n","\n","\n","        # RGB image with higher brightness\n","        red_norm = (red - np.min(red)) / (np.max(red) - np.min(red))\n","        green_norm = (green - np.min(green)) / (np.max(green) - np.min(green))\n","        blue_norm = (blue - np.min(blue)) / (np.max(blue) - np.min(blue))\n","        pseudo_RGB_image = np.dstack((red_norm, green_norm, blue_norm))\n","\n","        pseudo_RGB_image_normalized = (pseudo_RGB_image - np.min(pseudo_RGB_image)) / (\n","            pseudo_RGB_image.max() - pseudo_RGB_image.min()\n","        )\n","\n","\n","        pseudo_RGB_image_brighter = pseudo_RGB_image_normalized * brightness\n","        pseudo_RGB_image_brighter = np.clip(pseudo_RGB_image_brighter, 0, 1)\n","\n","        if backend ==\"matplotlib\":\n","            plt.figure(figsize=figure_size)\n","            plt.imshow(pseudo_RGB_image_brighter)\n","            plt.title(f\"{city} RGB Image\")\n","            plt.axis(\"off\")\n","            # plt.show()\n","            plt.savefig(os.path.join(image_path_out, f\"{city}_RGB_Brighter.png\"))\n","            if show_plot:\n","                plt.show()\n","            plt.close()\n","\n","            # single band img\n","            # single_band = satellite_image.read(1)\n","            single_band_stretched = stretch_hist(red)\n","            plt.figure(figsize=figure_size)\n","            plt.imshow(single_band_stretched, cmap=\"gray\")\n","            plt.title(f\"{city} Single Band Image\")\n","            plt.axis(\"off\")\n","            # plt.show()\n","            plt.savefig(os.path.join(image_path_out, f\"{city}_SingleBand.png\"))\n","            if show_plot:\n","                plt.show()\n","            plt.close()\n","        elif backend == \"plotly\":\n","\n","            # plot the mask\n","            fig = px.imshow(mask.astype(np.uint8), binary_string=True)\n","\n","            # Overlay the mask with the image\n","            fig.add_trace(go.Image(z=(pseudo_RGB_image_brighter * 255).astype(np.uint8), opacity=1))\n","\n","\n","            # Update layout with a button to toggle mask visibility\n","            fig.update_layout(\n","                updatemenus=[\n","                    dict(\n","                        type=\"buttons\",\n","                        direction=\"left\",\n","                        buttons=list([\n","                            dict(\n","                                args=[{\"opacity\": [0,1]}],\n","                                label=\"Hide Mask\",\n","                                method=\"restyle\"\n","                            ),\n","                            dict(\n","                                args=[{\"opacity\": [0.5, 0.5]}],\n","                                label=\"Show Mask\",\n","                                method=\"restyle\"\n","                            )\n","                        ]),\n","                    ),\n","                ],\n","                xaxis=dict(\n","                    scaleanchor=\"y\",\n","                    scaleratio=1\n","                ),\n","                yaxis=dict(\n","                    scaleanchor=\"x\",\n","                    scaleratio=1\n","                )\n","            )\n","\n","            # Enable zooming and panning\n","            fig.update_xaxes(constrain='domain')\n","            fig.update_yaxes(scaleanchor='x', scaleratio=1)\n","            fig.update_layout(height=1000, width=1000)\n","\n","            # Display the figure\n","            return fig\n","\n","\n","        # B8 B4 B3 -> False Color\n","        b8 = satellite_data[...,3]\n","        b8_stretched = stretch_hist(b8)\n","        b4 = red_stretched\n","        b3 = green_stretched\n","\n","        false_color = np.dstack((b8_stretched, b4, b3))\n","        plt.figure(figsize=figure_size)\n","        plt.imshow(false_color)\n","        plt.title(f\"{city} False Color Image\")\n","        plt.axis(\"off\")\n","        # plt.show()\n","        plt.savefig(os.path.join(image_path_out, f\"{city}_FalseColor.png\"))\n","        if show_plot:\n","            plt.show()\n","        plt.close()\n","\n","        # params[\"bands\"] = [\"B04\", \"B03\", \"B02\", \"B08\", \"B12\", \"B11\", \"SCL\"] # scl must be last\n","\n","        # B12, B11, B4 -> False Color Urban\n","        b12 = satellite_data[...,4]\n","        b11 = satellite_data[...,5]\n","        b04 = red\n","        b12_norm = (b12 - np.min(b12)) / (np.max(b12) - np.min(b12))\n","        b11_norm = (b11 - np.min(b11)) / (np.max(b11) - np.min(b11))\n","        b04_norm = (b04 - np.min(b04)) / (np.max(b04) - np.min(b04))\n","\n","\n","        false_color_urban = np.dstack((b12_norm, b11_norm, b04_norm)) * brightness\n","        false_color_urban = np.clip(false_color_urban, 0, 1)\n","\n","        plt.figure(figsize=figure_size)\n","        plt.imshow(false_color_urban)\n","        plt.title(f\"{city} False Color Urban Image\")\n","        plt.axis(\"off\")\n","        # plt.show()\n","        plt.savefig(os.path.join(image_path_out, f\"{city}_FalseColorUrban.png\"))\n","        if show_plot:\n","            plt.show()\n","        plt.close()\n","\n","\n","        # get vegetation_index\n","        def vegetation_index(band1, band2):\n","            return (band1 - band2) / (band1 + band2)\n","\n","\n","        ndvi = vegetation_index(satellite_data[...,3], satellite_data[...,2])\n","        plt.figure(figsize=figure_size)\n","        plt.imshow(ndvi, cmap=\"RdYlGn\")\n","        plt.title(f\"{city} NDVI Image\")\n","        plt.axis(\"off\")\n","        # plt.show()\n","        plt.savefig(os.path.join(image_path_out, f\"{city}_NDVI.png\"))\n","        if show_plot:\n","            plt.show()\n","        plt.close()\n","\n","        # Visualize the mask\n","        plt.figure(figsize=(10, 10))\n","        plt.imshow(mask, cmap=\"Blues\")\n","        plt.title(f\"{city} Building Mask\")\n","        plt.axis(\"off\")\n","        # plt.show()\n","        plt.savefig(os.path.join(image_path_out, f\"{city}_BuildingMask.png\"))\n","        if show_plot:\n","            plt.show()\n","        plt.close()\n","\n","\n","        # Load the image\n","        img = single_band_stretched  # Assuming `blue_stretched` is the single band image\n","        blue_cmap = plt.cm.Blues\n","        blue_building_mask = blue_cmap(mask / mask.max())\n","        blue_building_mask[..., 2] = mask * 0.8\n","\n","        # Plot the image\n","        plt.figure(figsize=(10, 10))\n","        plt.imshow(img, cmap=\"gray\", alpha=1)\n","\n","        plt.imshow(blue_building_mask)\n","\n","        # Set the title and axis labels\n","        plt.title(f\"{city} Image with Buildings Mask\")\n","        plt.axis(\"off\")\n","\n","        # Show the plot\n","        # plt.show()\n","        plt.savefig(os.path.join(image_path_out, f\"{city}_BuildingMaskOverlay.png\"))\n","        if show_plot:\n","            plt.show()\n","        plt.close()\n","\n","\n","def create_tensor_of_windows(image, mask, patch_size=128):\n","    \"\"\"\n","    Create tensor with dimensions [N, H, W, C+1] from the satellite image of the city.\n","    image should be of shape (H, W, C)\n","    mask should be of shape (H, W, 1)\n","    \"\"\"\n","    # Merge Mask onto Image\n","    image_with_mask = np.dstack((image, mask))\n","\n","    # cut of edges so image shape is divisible by patch size\n","    reduced_image = image_with_mask[:-(image_with_mask.shape[0]%patch_size), :-(image_with_mask.shape[1]%patch_size)]\n","\n","    # calculate number of patches\n","    N = reduced_image.shape[0]//patch_size*reduced_image.shape[1]//patch_size\n","\n","    # initialize target array\n","    target_array = np.zeros((N, patch_size, patch_size, reduced_image.shape[-1]), dtype=np.uint16)\n","\n","    # fill target array\n","    for row in range(patch_size):\n","        for col in range(patch_size):\n","            # calculate row and column indices\n","            row_filter = range(row,reduced_image.shape[0]+row,patch_size)\n","            col_filter = range(col,reduced_image.shape[1]+col,patch_size)\n","\n","            # write values into target array\n","            target_array[:, row, col, :] = reduced_image[row_filter][:,col_filter,:].reshape(-1, reduced_image.shape[-1])\n","\n","    return target_array\n","\n","   \n","def divide_into_test_training(data, test_ratio=0.2, validation_ratio=0, seed=42):\n","    \"\"\"\n","    Divide the data into test and training split with seed.\n","    \"\"\"\n","    \n","    # Define the split rati\n","    train_ratio = 1 - test_ratio - validation_ratio\n","    if train_ratio < 0:\n","        raise ValueError(\"The train ratio is negative. Please check the split ratios.\")\n","\n","    # # Calculate the sizes for training and test sets\n","    # train_size = int(train_ratio * len(data))\n","    # test_size = int(test_ratio * len(data))\n","    # validation_size = int(validation_ratio * len(data))\n","\n","    # Split the dataset with seed\n","    generator = torch.Generator().manual_seed(seed)\n","    train_dataset, test_dataset, validation_dataset = random_split(data, [train_ratio, test_ratio, validation_ratio], generator=generator)\n","\n","    return train_dataset, test_dataset, validation_dataset\n","\n","\n","def validate_test_training_validation_split(train_dataset, test_dataset, validation_dataset, city_names=None):\n","    \"\"\"\n","    Validate the train to the test split and the train to the validation split.\n","    \"\"\"\n","    logger = logging.getLogger()\n","    # take out dataset for better readabiltiy\n","    dataset = train_dataset.dataset[:,:-2]\n","\n","    # calculate mean, std, min and max for each image\n","    means = dataset.mean(axis=(2,3))\n","    stds = dataset.std(axis=(2,3))\n","    mins = dataset.min(axis=(2,3))\n","    maxs = dataset.max(axis=(2,3))\n","\n","    # create dataframes for train, test and validation set\n","    train_means = pd.DataFrame({\n","        \"mean\":means[train_dataset.indices].mean(axis=0), \n","        \"std\":stds[train_dataset.indices].mean(axis=0),\n","        \"min\":mins[train_dataset.indices].mean(axis=0),\n","        \"max\":maxs[train_dataset.indices].mean(axis=0),\n","        }, index=[\"R\", \"G\", \"B\",\"B08\", \"B12\", \"B11\"])\n","\n","    test_means = pd.DataFrame({\n","        \"mean\":means[test_dataset.indices].mean(axis=0), \n","        \"std\":stds[test_dataset.indices].mean(axis=0),\n","        \"min\":mins[test_dataset.indices].mean(axis=0),\n","        \"max\":maxs[test_dataset.indices].mean(axis=0),\n","        }, index=[\"R\", \"G\", \"B\",\"B08\", \"B12\", \"B11\"])\n","\n","    # test if differences between train and test set are below 10%\n","    if (((train_means-test_means)/train_means)<0.1).all().all():\n","        print(u'\\u2713',\"Differences of train and test set is below 10% on mean, std, min and max across all input bands\",)\n","    else:\n","        # if not show differences and give out Warning\n","        temp_df =(train_means-test_means)/train_means\n","        logger.warning(\"Differences of train and test set is above 10% on one of mean, std, min and max across all input bands. This might be too big of a difference between train and test set. Please choose another seed for splitting.\")\n","        print(\"!!!There might be large diffferecenes between train and test set. Please choose another seed for splitting. For more detail see the differences below\",)\n","        print(temp_df[temp_df>0.1].dropna(axis=1, how='all').dropna(axis=0, how='all'))\n","        \n","    if validation_dataset.indices:\n","        validation_means = pd.DataFrame({\n","            \"mean\":means[validation_dataset.indices].mean(axis=0), \n","            \"std\":stds[validation_dataset.indices].mean(axis=0),\n","            \"min\":mins[validation_dataset.indices].mean(axis=0),\n","            \"max\":maxs[validation_dataset.indices].mean(axis=0),\n","            }, index=[\"R\", \"G\", \"B\",\"B08\", \"B12\", \"B11\"])\n","        \n","        # test if differences between train and validation set are below 10%\n","        if (((train_means-validation_means)/train_means)<0.1).all().all():\n","            print(u'\\u2713',\"Differences of train and validation set is below 10% on mean, std, min and max across all input bands\",)\n","        else:\n","            # if not show differences and give out Warning\n","            temp_df =(train_means-validation_means)/train_means\n","            logger.warning(\"Differences of train and validation set is above 10% on one of mean, std, min and max across all input bands. This might be too big of a difference between train and test set. Please choose another seed for splitting.\")\n","            print(\"!!!There might be large diffferecenes between train and validation set. Please choose another seed for splitting. For more detail see the differences below\",)\n","            print(temp_df[temp_df>0.1].dropna(axis=1, how='all').dropna(axis=0, how='all'))\n","\n","    print()\n","    # Look at distribution of masks\n","    masks  = train_dataset.dataset[:,[-2]]\n","\n","    # sum the pixels of building up over each image\n","    sum = masks.sum(axis=(2,3))\n","\n","    # create dataframes for train, test and validation set with descriptive statistics\n","    train_means_labels = pd.DataFrame({\n","        \"mean\":sum[train_dataset.indices].mean(axis=0), \n","        \"median\":np.median(sum[train_dataset.indices],axis=0), \n","        \"std\":sum[train_dataset.indices].std(axis=0),\n","        \"10th percentile\":np.percentile(sum[train_dataset.indices], q=10,axis=0),\n","        \"90th percentile\":np.percentile(sum[train_dataset.indices], q=90,axis=0),\n","        }, index=[\"Train\"])\n","    test_means_labels = pd.DataFrame({\n","        \"mean\":sum[test_dataset.indices].mean(axis=0),\n","        \"median\":np.median(sum[test_dataset.indices],axis=0), \n","        \"std\":sum[test_dataset.indices].std(axis=0),\n","        \"10th percentile\":np.percentile(sum[test_dataset.indices], q=10,axis=0),\n","        \"90th percentile\":np.percentile(sum[test_dataset.indices], q=90,axis=0),\n","        }, index=[\"Test\"])\n","    if validation_dataset.indices:\n","        validation_means_labels = pd.DataFrame({\n","            \"mean\":sum[validation_dataset.indices].mean(axis=0), \n","            \"median\":np.median(sum[validation_dataset.indices],axis=0), \n","            \"std\":sum[validation_dataset.indices].std(axis=0),\n","            \"10th percentile\":np.percentile(sum[validation_dataset.indices], q=10,axis=0),\n","            \"90th percentile\":np.percentile(sum[validation_dataset.indices], q=90,axis=0),\n","            }, index=[\"Validation\"])\n","        # print concatenated dataframes\n","        print(\"Comparison of distribution of masks:\\n\",pd.concat([train_means_labels, test_means_labels, validation_means_labels]))\n","    else:\n","        print(\"Comparison of distribution of masks:\\n\", pd.concat([train_means_labels, test_means_labels] ))\n","\n","    print()\n","\n","    # look at the distribution of the data according to the different cities\n","    if city_names is not None:  \n","        # take out the city name for each label\n","        train_cities = train_dataset.dataset[:,-1,0,0][train_dataset.indices]\n","        test_cities = test_dataset.dataset[:,-1,0,0][test_dataset.indices]\n","        validation_cities = validation_dataset.dataset[:,-1,0,0][validation_dataset.indices]\n","\n","        # lookup how often each city occured in the different sets\n","        train_city_counts = np.unique(train_cities, return_counts=True)\n","        test_city_counts = np.unique(test_cities, return_counts=True)\n","        validation_citiy_counts = np.unique(validation_cities, return_counts=True)\n","\n","        # create dataframes for better readability\n","        df = pd.DataFrame({\n","            \"Train\":pd.Series(train_city_counts[1]/train_cities.shape[0], index=train_city_counts[0], name='train'),\n","            \"Test\":pd.Series(test_city_counts[1]/test_cities.shape[0], index=test_city_counts[0], name='test'),\n","            \"Validation\":pd.Series(validation_citiy_counts[1]/validation_cities.shape[0], index=validation_citiy_counts[0], name='validation')})\n","        print(df.index)\n","        df.index = df.index.map({i:c for i ,c in enumerate(city_names)})\n","        print(\"Comparison of cities the data in the differen sets originates from:\\n\",df.T)\n","\n","\n","\n","\n","def create_data_loaders(train_dataset, test_dataset, validation_dataset, batch_size = 64):\n","    \"\"\"\n","    Create DataLoaders.\n","    \"\"\"\n","    # Create DataLoaders\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, test_loader, validation_loader\n","\n","\n","def apply_preprocessing_pipeline(images, masks, patch_size = 128, test_ratio = 0.2,validation_ratio=0, batch_size = 64, show_validation_of_split=True, city_names=None, minimum_number_of_true_pixels_per_image=0):\n","    \"\"\"\n","    applies windowing, deviding into train and test and creating data loaders.\n","    \"\"\"\n","\n","    # for each city create patched images\n","    patched_images = []\n","    for i,(image, mask ) in enumerate(zip(images, masks)):\n","        patched_image = create_tensor_of_windows(image, mask, patch_size=patch_size)\n","        city = np.ones(shape=list(patched_image.shape[:-1])+[1])*i\n","        patched_image_with_city = np.concatenate([patched_image, city], axis=-1)\n","        patched_images.append(patched_image_with_city)\n","\n","\n","    # concatenate all patched images\n","    patched_images_merged = np.concatenate(patched_images, axis=0)\n","\n","    # reorder axis to [N, C, H, W] for torch\n","    patched_images_merged = np.transpose(patched_images_merged, (0,3,1,2))\n","    \n","    # discard images with less than minimum_number_of_true_pixels_per_image\n","    sums = patched_images_merged[:,-2].sum(axis=(1,2))\n","    patched_images_merged = patched_images_merged[sums>=minimum_number_of_true_pixels_per_image]\n","\n","    # devide into train and test\n","    train_dataset, test_dataset, validation_dataset = divide_into_test_training(patched_images_merged, test_ratio=test_ratio, validation_ratio=validation_ratio)\n","\n","    if show_validation_of_split:\n","        validate_test_training_validation_split(train_dataset, test_dataset, validation_dataset, city_names=city_names)\n","\n","    dataset = train_dataset.dataset[:,:-1]\n","    train_dataset.dataset = dataset\n","    test_dataset.dataset = dataset\n","    validation_dataset.dataset = dataset    \n","    # create data loaders\n","    train_loader, test_loader , validation_loader= create_data_loaders(train_dataset, test_dataset,validation_dataset, batch_size=batch_size)\n","\n","    # TODO fix error\n","    # TODO remove city names\n","\n","    return train_loader, test_loader, validation_loader\n","\n","\n","def plot_sub_image( image_data):\n","    \"\"\"\n","    Plot sub image.\n","    \"\"\"\n","    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n","\n","    ax[0].imshow(stretch_hist(image_data[:,:,:3]))\n","    ax[1].imshow(stretch_hist(image_data[:,:,-1]))\n","    return fig\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T11:54:09.441974Z","iopub.status.busy":"2024-06-28T11:54:09.441608Z","iopub.status.idle":"2024-06-28T12:00:09.778626Z","shell.execute_reply":"2024-06-28T12:00:09.777648Z","shell.execute_reply.started":"2024-06-28T11:54:09.441944Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openeo\n","  Downloading openeo-0.30.0-py3-none-any.whl.metadata (7.3 kB)\n","Collecting pyrosm\n","  Downloading pyrosm-0.6.2.tar.gz (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from openeo) (2.32.3)\n","Requirement already satisfied: shapely>=1.6.4 in /opt/conda/lib/python3.10/site-packages (from openeo) (1.8.5.post1)\n","Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from openeo) (1.26.4)\n","Requirement already satisfied: xarray>=0.12.3 in /opt/conda/lib/python3.10/site-packages (from openeo) (2024.5.0)\n","Requirement already satisfied: pandas>0.20.0 in /opt/conda/lib/python3.10/site-packages (from openeo) (2.2.1)\n","Collecting pystac>=1.5.0 (from openeo)\n","  Downloading pystac-1.10.1-py3-none-any.whl.metadata (6.4 kB)\n","Requirement already satisfied: deprecated>=1.2.12 in /opt/conda/lib/python3.10/site-packages (from openeo) (1.2.14)\n","Collecting python-rapidjson (from pyrosm)\n","  Downloading python_rapidjson-1.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n","Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.10/site-packages (from pyrosm) (69.0.3)\n","Requirement already satisfied: geopandas>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from pyrosm) (0.14.4)\n","Collecting shapely>=1.6.4 (from openeo)\n","  Downloading shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n","Collecting cykhash (from pyrosm)\n","  Downloading cykhash-2.0.1.tar.gz (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hCollecting pyrobuf (from pyrosm)\n","  Using cached pyrobuf-0.9.3-cp310-cp310-linux_x86_64.whl\n","Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.12->openeo) (1.14.1)\n","Requirement already satisfied: fiona>=1.8.21 in /opt/conda/lib/python3.10/site-packages (from geopandas>=0.12.0->pyrosm) (1.9.6)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from geopandas>=0.12.0->pyrosm) (21.3)\n","Requirement already satisfied: pyproj>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from geopandas>=0.12.0->pyrosm) (3.6.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>0.20.0->openeo) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>0.20.0->openeo) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>0.20.0->openeo) (2023.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->openeo) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->openeo) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->openeo) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->openeo) (2024.2.2)\n","Collecting packaging (from geopandas>=0.12.0->pyrosm)\n","  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: jinja2>=2.8 in /opt/conda/lib/python3.10/site-packages (from pyrobuf->pyrosm) (3.1.2)\n","Requirement already satisfied: cython>=0.23 in /opt/conda/lib/python3.10/site-packages (from pyrobuf->pyrosm) (3.0.8)\n","Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (23.2.0)\n","Requirement already satisfied: click~=8.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (8.1.7)\n","Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (1.1.1)\n","Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (0.7.2)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.8->pyrobuf->pyrosm) (2.1.3)\n","Downloading openeo-0.30.0-py3-none-any.whl (260 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.2/260.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pystac-1.10.1-py3-none-any.whl (182 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.9/182.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading python_rapidjson-1.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pyrosm, cykhash\n","  Building wheel for pyrosm (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pyrosm: filename=pyrosm-0.6.2-cp310-cp310-linux_x86_64.whl size=2927743 sha256=949e6f624ed6541ae4a7adb40744343ccfa5fc0a19eea68ae57261a36685acb9\n","  Stored in directory: /root/.cache/pip/wheels/18/21/22/b07b96a708420e351c553188667cfd6ebc7e78a011a8708cf4\n","  Building wheel for cykhash (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for cykhash: filename=cykhash-2.0.1-cp310-cp310-linux_x86_64.whl size=786067 sha256=8c862b2daab5f93466cf1ecb99f5868af0dfea501b028663359aca613888d790\n","  Stored in directory: /root/.cache/pip/wheels/ed/de/7a/4386df8e70276a0d2ec5e990db76b6c89889dc41cd627e1c14\n","Successfully built pyrosm cykhash\n","Installing collected packages: cykhash, shapely, python-rapidjson, packaging, pystac, pyrobuf, pyrosm, openeo\n","  Attempting uninstall: shapely\n","    Found existing installation: Shapely 1.8.5.post1\n","    Uninstalling Shapely-1.8.5.post1:\n","      Successfully uninstalled Shapely-1.8.5.post1\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.4.1 requires cubinlinker, which is not installed.\n","cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.4.1 requires ptxcompiler, which is not installed.\n","cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","keras-cv 0.9.0 requires keras-core, which is not installed.\n","keras-nlp 0.12.1 requires keras-core, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","distributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n","jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cykhash-2.0.1 openeo-0.30.0 packaging-24.1 pyrobuf-0.9.3 pyrosm-0.6.2 pystac-1.10.1 python-rapidjson-1.17 shapely-2.0.4\n"]}],"source":["!pip install openeo pyrosm"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:04:01.550854Z","iopub.status.busy":"2024-06-28T12:04:01.550020Z","iopub.status.idle":"2024-06-28T12:04:14.926796Z","shell.execute_reply":"2024-06-28T12:04:14.925959Z","shell.execute_reply.started":"2024-06-28T12:04:01.550823Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-28 12:04:04.283577: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-28 12:04:04.283699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-28 12:04:04.472173: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["# basics\n","import numpy as np\n","from tqdm.notebook import tqdm \n","\n","\n","# torch\n","import torch\n","from torch.utils.data import Dataset\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.tensorboard import SummaryWriter\n","\n","\n","\n","\n","# Configure logging for the pipeline\n","logger = setup_logger(level='INFO')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:04:15.907786Z","iopub.status.busy":"2024-06-28T12:04:15.906871Z","iopub.status.idle":"2024-06-28T12:04:15.913219Z","shell.execute_reply":"2024-06-28T12:04:15.912385Z","shell.execute_reply.started":"2024-06-28T12:04:15.907749Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-28 12:04:15,909 - root - INFO - __init__ - Data directory already exists\n"]}],"source":["cities = ['Aachen', 'CapeTown', 'Hamburg', 'Johannesburg', 'London', 'Montreal', 'Paris', 'Seoul', 'Singapore', 'Sydney']\n","\n","datahandler = DataHandler(logger)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:04:35.990951Z","iopub.status.busy":"2024-06-28T12:04:35.990512Z","iopub.status.idle":"2024-06-28T12:05:09.799733Z","shell.execute_reply":"2024-06-28T12:05:09.798767Z","shell.execute_reply.started":"2024-06-28T12:04:35.990918Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"120ac29cfc2446f5bc9af7d5c99bd812","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2024-06-28 12:04:36,008 - root - INFO - get_satellite_image - Aachen: Using local satellite image\n","2024-06-28 12:04:36,103 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Aachen/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","2024-06-28 12:04:36,919 - root - INFO - get_building_mask - Aachen: Using local building mask\n","2024-06-28 12:04:37,001 - root - INFO - get_building_mask - Aachen: Using local building mask\n","2024-06-28 12:04:37,092 - root - INFO - get_satellite_image - CapeTown: Using local satellite image\n","2024-06-28 12:04:37,097 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/CapeTown/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","2024-06-28 12:04:39,440 - root - INFO - get_building_mask - CapeTown: Using local building mask\n","2024-06-28 12:04:39,704 - root - INFO - get_building_mask - CapeTown: Using local building mask\n","2024-06-28 12:04:40,020 - root - INFO - get_satellite_image - Hamburg: Using local satellite image\n","2024-06-28 12:04:40,025 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Hamburg/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","2024-06-28 12:04:42,234 - root - INFO - get_building_mask - Hamburg: Using local building mask\n","2024-06-28 12:04:42,487 - root - INFO - get_building_mask - Hamburg: Using local building mask\n","2024-06-28 12:04:42,754 - root - INFO - get_satellite_image - Johannesburg: Using local satellite image\n","2024-06-28 12:04:42,758 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Johannesburg/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","2024-06-28 12:04:48,917 - root - INFO - get_building_mask - Johannesburg: Using local building mask\n","2024-06-28 12:04:49,587 - root - INFO - get_building_mask - Johannesburg: Using local building mask\n","2024-06-28 12:04:50,176 - root - INFO - get_satellite_image - London: Using local satellite image\n","2024-06-28 12:04:50,183 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/London/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","2024-06-28 12:04:55,348 - root - INFO - get_building_mask - London: Using local building mask\n","2024-06-28 12:04:55,945 - root - INFO - get_building_mask - London: Using local building mask\n","2024-06-28 12:04:56,225 - root - INFO - get_satellite_image - Montreal: Using local satellite image\n","2024-06-28 12:04:56,229 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Montreal/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","2024-06-28 12:05:00,636 - root - INFO - get_building_mask - Montreal: Using local building mask\n","2024-06-28 12:05:00,895 - root - INFO - get_building_mask - Montreal: Using local building mask\n","2024-06-28 12:05:01,157 - root - INFO - get_satellite_image - Paris: Using local satellite image\n","2024-06-28 12:05:01,162 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Paris/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","2024-06-28 12:05:01,425 - root - INFO - get_building_mask - Paris: Using local building mask\n","2024-06-28 12:05:01,444 - root - INFO - get_building_mask - Paris: Using local building mask\n","2024-06-28 12:05:01,465 - root - INFO - get_satellite_image - Seoul: Using local satellite image\n","2024-06-28 12:05:01,469 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Seoul/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","2024-06-28 12:05:05,306 - root - INFO - get_building_mask - Seoul: Using local building mask\n","2024-06-28 12:05:05,528 - root - INFO - get_building_mask - Seoul: Using local building mask\n","2024-06-28 12:05:05,740 - root - INFO - get_satellite_image - Singapore: Using local satellite image\n","2024-06-28 12:05:05,745 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Singapore/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","2024-06-28 12:05:07,048 - root - INFO - get_building_mask - Singapore: Using local building mask\n","2024-06-28 12:05:07,120 - root - INFO - get_building_mask - Singapore: Using local building mask\n","2024-06-28 12:05:07,194 - root - INFO - get_satellite_image - Sydney: Using local satellite image\n","2024-06-28 12:05:07,198 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Sydney/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n","2024-06-28 12:05:09,535 - root - INFO - get_building_mask - Sydney: Using local building mask\n","2024-06-28 12:05:09,668 - root - INFO - get_building_mask - Sydney: Using local building mask\n"]}],"source":["# load images and mask for all specified cites\n","\n","import os\n","images = []\n","sparse_masks=[]\n","dense_masks=[]\n","\n","for city in tqdm(cities):\n","    buildings = None\n","    images.append(datahandler.get_satellite_image(city))\n","    sparse_masks.append(datahandler.get_building_mask(city, all_touched=False, loaded_buildings=buildings))\n","    dense_masks.append(datahandler.get_building_mask(city, all_touched=True, loaded_buildings=buildings))"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:06:29.669768Z","iopub.status.busy":"2024-06-28T12:06:29.669306Z","iopub.status.idle":"2024-06-28T12:07:22.766365Z","shell.execute_reply":"2024-06-28T12:07:22.765109Z","shell.execute_reply.started":"2024-06-28T12:06:29.669728Z"},"trusted":true},"outputs":[],"source":["# apply training pipeline\n","# TODO make train test split consistent so we can train with multiple sizes, dont know if there is an advantage though\n","train_loader, test_loader = apply_preprocessing_pipeline(images, sparse_masks, patch_size = 128, train_ratio = 0.8, batch_size = 64)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:08:14.615975Z","iopub.status.busy":"2024-06-28T12:08:14.614977Z","iopub.status.idle":"2024-06-28T12:08:14.620195Z","shell.execute_reply":"2024-06-28T12:08:14.619310Z","shell.execute_reply.started":"2024-06-28T12:08:14.615938Z"},"trusted":true},"outputs":[],"source":["patch_size = 128\n","train_ratio = 0.8\n","batch_size = 64"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:09:08.240527Z","iopub.status.busy":"2024-06-28T12:09:08.240086Z","iopub.status.idle":"2024-06-28T12:10:00.454518Z","shell.execute_reply":"2024-06-28T12:10:00.453470Z","shell.execute_reply.started":"2024-06-28T12:09:08.240483Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cedb8e20d504209a3f6515809ac6b25","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["patched_images = []\n","masks = sparse_masks\n","for image, mask in tqdm(zip(images, masks)):\n","    patched_images.append(create_tensor_of_windows(image, mask, patch_size=patch_size))\n","\n","# concatenate all patched images\n","patched_images_merged = np.concatenate(patched_images, axis=0)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:15:12.438345Z","iopub.status.busy":"2024-06-28T12:15:12.437430Z","iopub.status.idle":"2024-06-28T12:15:13.123513Z","shell.execute_reply":"2024-06-28T12:15:13.122558Z","shell.execute_reply.started":"2024-06-28T12:15:12.438311Z"},"trusted":true},"outputs":[],"source":[" patched_images_merged_reduced = patched_images_merged[~(patched_images_merged[...,-1].sum(axis=1).sum(axis=1)<1)]"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:15:13.845951Z","iopub.status.busy":"2024-06-28T12:15:13.845565Z","iopub.status.idle":"2024-06-28T12:15:13.852378Z","shell.execute_reply":"2024-06-28T12:15:13.851174Z","shell.execute_reply.started":"2024-06-28T12:15:13.845922Z"},"trusted":true},"outputs":[],"source":["# reorder axis to [N, C, H, W] for torch\n","patched_images_merged_reduced = np.transpose(patched_images_merged_reduced, (0,3,1,2))\n","\n","# devide into train and test\n","train_ds, test_ds = divide_into_test_training(patched_images_merged_reduced,train_ratio=train_ratio)\n","\n","# create data loaders\n","train_loader, test_loader = create_data_loaders(train_ds, test_ds, batch_size=batch_size)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:15:15.864162Z","iopub.status.busy":"2024-06-28T12:15:15.863452Z","iopub.status.idle":"2024-06-28T12:15:15.895503Z","shell.execute_reply":"2024-06-28T12:15:15.894764Z","shell.execute_reply.started":"2024-06-28T12:15:15.864131Z"},"trusted":true},"outputs":[],"source":["# initialize model, taken from exercise pdf\n","model = nn.Sequential(\n","    nn.Conv2d(6, 32, kernel_size=3, padding=1), nn.ReLU(),\n","    nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),\n","    nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),\n","    nn.Conv2d(128, 1, kernel_size=1, padding=0),\n","    nn.Sigmoid())\n","\n","# initialize tensorboard writer\n","writer = SummaryWriter()"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:15:53.088963Z","iopub.status.busy":"2024-06-28T12:15:53.088556Z","iopub.status.idle":"2024-06-28T12:15:53.137639Z","shell.execute_reply":"2024-06-28T12:15:53.136546Z","shell.execute_reply.started":"2024-06-28T12:15:53.088929Z"},"trusted":true},"outputs":[{"ename":"AttributeError","evalue":"'DataLoader' object has no attribute 'to'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'to'"]}],"source":[]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-06-28T12:15:17.736016Z","iopub.status.busy":"2024-06-28T12:15:17.735158Z","iopub.status.idle":"2024-06-28T12:15:19.304856Z","shell.execute_reply":"2024-06-28T12:15:19.303607Z","shell.execute_reply.started":"2024-06-28T12:15:17.735980Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4bd8a618a084cd7b43fb787dd2140b6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"TypeError","evalue":"can't convert np.ndarray of type numpy.uint16. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# splid in inputs and labels\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m batch[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     13\u001b[0m         labels \u001b[38;5;241m=\u001b[39m batch[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:171\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([torch\u001b[38;5;241m.\u001b[39mas_tensor(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:171\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n","\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.uint16. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."]}],"source":["# Instantiate the model, loss function, and optimizer\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","# Training loop\n","num_epochs = 50\n","\n","model.train()\n","for epoch in tqdm(range(num_epochs)):\n","    for batch in train_loader:\n","        # splid in inputs and labels\n","        inputs = batch[:,:-1].to(torch.float32)\n","        labels = batch[:,-1, np.newaxis].to(torch.float32)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward pass\n","        outputs = model(inputs)\n","\n","        # calculate loss\n","        loss = criterion(outputs, labels)\n","\n","        # write to tensorboard\n","        writer.add_scalar(\"Loss/train\", loss, epoch)\n","\n","        # backward pass\n","        loss.backward()\n","\n","        # optimizer step\n","        optimizer.step()\n","    \n"]},{"cell_type":"markdown","metadata":{},"source":["## Save Model"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["import os\n","\n","os.makedirs(\"saved_models\", exist_ok=True)\n","torch.save(model.state_dict(), \"saved_models/model1\")"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["t  = torch.Tensor(test_loader.dataset)\n","\n","# splid in inputs and labels\n","test_inputs = t[:,:-1]#.to(torch.float32)\n","test_labels = t[:,-1, np.newaxis]#.to(torch.float32)\n","\n","test_results = model(test_inputs).detach()\n","\n","# see how many percnet where predicted right\n","threshold = 0.5\n","((test_results>threshold)==test_labels).sum()/np.prod(test_labels.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import RocCurveDisplay\n","\n","RocCurveDisplay.from_predictions(\n","   test_labels.flatten(), test_results.flatten())"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["writer.flush()"]},{"cell_type":"markdown","metadata":{},"source":["# Download"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","buildings = []\n","sat_images = []\n","building_masks = []\n","\n","for city in cities: \n","    buildings.append(datahandler.get_buildings(city))\n","    sat_images.append(datahandler.get_satellite_image(city))\n","    building_masks.append(datahandler.get_building_mask(city))\n","\n","# Plot the expected results for the first city \n","datahandler.plot(city[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import data_preparation\n","\n","for city in cities:\n","    data_preparation.create_tensor(city)"]},{"cell_type":"markdown","metadata":{},"source":["# Download"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download \n","\n","for city in cities: \n","    sat_image = datahandler.get_satellite_image(city)\n","    mask = datahandler.get_building_mask(city)\n","\n","# Plot the expected results for the first city \n","datahandler.plot(city[0])"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5299351,"sourceId":8810391,"sourceType":"datasetVersion"}],"dockerImageVersionId":30734,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
