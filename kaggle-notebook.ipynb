{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8810391,"sourceType":"datasetVersion","datasetId":5299351}],"dockerImageVersionId":30734,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#basics\nimport os\nimport time\nimport json\nimport pickle\nimport openeo\nimport numpy as np\n\n# geography\nimport geopandas as gpd\nimport rasterio\nfrom rasterio.features import geometry_mask\n\n\n#download\nimport pyrosm as pyr\nfrom openeo.rest import OpenEoApiError\nfrom openeo.processes import ProcessBuilder, if_, is_nan\n\n\n\n# plotting \nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport logging\nfrom pyrosm.data import sources\nimport numpy as np\n\ndef setup_logger(level: int = logging.INFO):\n    \"\"\"\n    Set up a logger for the pipeline. \n    \"\"\"\n    logger = logging.getLogger()\n    formatter = logging.Formatter(\n        \"%(asctime)s - %(name)s - %(levelname)s - %(funcName)s - %(message)s\"\n    )\n    \n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)\n    \n    file_handler = logging.FileHandler(\"main.log\")\n    file_handler.setFormatter(formatter)\n\n    logger.setLevel(level)\n    logger.addHandler(console_handler)\n    logger.addHandler(file_handler)\n\n    return logger\n\n\ndef get_available_cities():\n    \"\"\"\n    Return all available cities from pyrosm \n    \"\"\"\n    return sources.cities.available\n\n\ndef stretch_hist(band):\n    \"\"\"\n    Apply histogram stretching\"\"\"\n    p2, p98 = np.percentile(band, (0.5, 99.5))\n    return np.clip((band - p2) * 255.0 / (p98 - p2), 0, 255).astype(np.uint8)\n\n\nclass DataHandler: \n    def __init__(self, logger):\n        \"\"\"\n        Initialize the DataHandler class and define openeo params.\n        \"\"\"\n        self.logger = logger\n        self.openeo_temporal_extent = [\"2023-05-01\", \"2023-09-30\"]\n        self.openeo_bands = [\"B04\", \"B03\", \"B02\", \"B08\", \"B12\", \"B11\", \"SCL\"]\n        self.openeo_max_cloud_cover = 30\n        self.openeo_spatial_resolution = 10\n        self.openeo_connection = None\n        self.openeo_collections = None\n        self.openeo_jobs = None\n        \n        if not os.path.exists(\"/kaggle/input/building-prediction/\"):\n            os.makedirs(\"/kaggle/input/building-prediction/\")\n            logger.info(\"Created data directory\")\n        else:\n            logger.info(\"Data directory already exists\")\n\n\n    def create_directory(self, city: str):\n        \"\"\"\n        Create a directory for each city.\n        \"\"\"\n        os.makedirs(f\"/kaggle/input/building-prediction//{city}\", exist_ok=True)\n        self.logger.info(f\"{city}: Directory available\")\n\n\n    def get_buildings(self, city: str):\n        \"\"\"\n        Return buildings for a given city\n        \"\"\"\n        self.create_directory(city)\n        \n        # Check if local data for city is available\n        if \"buildings.geojson\" in os.listdir(f\"/kaggle/input/building-prediction/{city}\"):\n            self.logger.info(f\"{city}: Using local building data\")\n            return gpd.read_file(f\"/kaggle/input/building-prediction/{city}/buildings.geojson\")\n\n        # Download data for city\n        fp = pyr.get_data(city, directory=os.path.join(\"data\", city))\n        osm = pyr.OSM(fp)\n        self.logger.info(f\"{city}: Downloaded data to data/{city}\")\n\n        # Get bounding box for city\n        boundingbox = self.get_boundingbox(city, osm)\n\n        # Get the buildings of the city\n        buildings_geodf = osm.get_buildings()\n\n        # Remove buildings outside of the bounding box of the city\n        buildings_geodf = buildings_geodf.cx[boundingbox[0] : boundingbox[2], boundingbox[1] : boundingbox[3]]\n\n        # Save the data of the city\n        buildings_path = f\"/kaggle/input/building-prediction/{city}/buildings.geojson\"\n        buildings_geodf.to_file(buildings_path, driver=\"GeoJSON\")\n        self.logger.info(f\"{city}: Stored data to data/{city}/buildings.geojson\")\n\n        return buildings_geodf\n\n\n    def get_boundingbox(self, city: str, osm = None):\n        \"\"\"\n        Get the bounding box for a city.\n        \"\"\"\n\n        # Return bounding box for Berlin as specified in exercise sheet to ensure correct testing results\n        if city == \"Berlin\":\n            return [13.294333, 52.454927, 13.500205, 52.574409]\n\n        # Check if local bounds are available\n        bounds_path = f\"/kaggle/input/building-prediction/{city}/bounds.pkl\"\n        if os.path.exists(bounds_path):\n            with open(bounds_path, \"rb\") as f:\n                boundingbox = pickle.load(f)\n            return boundingbox\n        \n        # Ensure OSM data is available \n        if osm is None:\n            self.get_buildings(city=city)\n\n        # Get the boundaries\n        geoframe_bounds = osm.get_boundaries()\n        boundingbox = geoframe_bounds[geoframe_bounds[\"name\"] == city].total_bounds\n\n        # Check if bounding box is None\n        if np.isnan(boundingbox[0]) or np.isnan(boundingbox[1]) or np.isnan(boundingbox[2]) or np.isnan(boundingbox[3]):\n            self.logger.info(f\"{city}: Bounding box is None. Using total bounds instead\")\n            boundingbox = geoframe_bounds.total_bounds\n        self.logger.info(f\"{city}: Bounding box is {boundingbox}\")     \n\n        # Save total bounds to pickle file\n        with open(bounds_path, \"wb\") as f:\n            pickle.dump(boundingbox, f)\n        self.logger.info(f\"{city}: Saved bounds to data/{city}/bounds.pkl\")\n\n        return boundingbox\n    \n\n    def get_satellite_image(self, city: str, return_rasterio_dataset = False): \n        \"\"\"\n        Get satellite images for a city. Use local data if available. Returns an Array with (H, W, C) shape\n        \"\"\"\n        if os.path.exists(f\"/kaggle/input/building-prediction/{city}/openEO.tif\"):\n            self.logger.info(f\"{city}: Using local satellite image\")\n            ds = rasterio.open(f\"/kaggle/input/building-prediction/{city}/openEO.tif\")\n            if return_rasterio_dataset:\n                return ds\n            \n            # Read all channels\n            sat_data = ds.read()\n\n            # Transpose to (H, W, C)\n            sat_data = np.transpose(sat_data, (1, 2, 0))\n            return sat_data\n        else:\n            self.download_satellite_image(city)\n            return self.get_satellite_image(city)\n    \n\n    def connect_to_openeo(self):\n        \"\"\"\n        Connect to the openEO backend and \n        \"\"\"\n        if self.openeo_connection is None:\n            connection = openeo.connect(\"openeo.dataspace.copernicus.eu\")\n            connection.authenticate_oidc()\n            self.openeo_connection = connection\n\n            self.logger.info(\"Connected to openEO\")\n        else:\n            self.logger.info(\"Already connected to openEO\")\n\n\n    def download_satellite_image(self, city: str):\n        \"\"\"\n        Download satellite images for a city. Retry for 3 times if the job fails or takes longer than 30 min per job.\n        \"\"\"\n        self.connect_to_openeo()\n        \n        # Log the currently running jobs\n        self.logger.info(\"Current jobs:\")\n        for idx, job in enumerate(self.openeo_connection.list_jobs()):\n            self.logger.info(f\"{idx} {job['id']} {job['status']}\")\n\n        # Retry job up to 3 times. Raise exception after 3 retries.\n        job_finished = False\n        job_number_of_retries = 0\n        while not job_finished : \n            if job_number_of_retries > 3:\n                self.logger.error(f\"{city}: Job failed after 3 retries\")\n                raise Exception(f\"{city}: Job failed after 3 retries\")\n            job = self.create_and_start_openeo_job(city)    \n            job_finished = self.await_job(city, job)\n            job_number_of_retries += 1\n\n        # Get job results and store in data/city\n        job_results = self.openeo_connection.job(job.job_id).get_results()\n        job_results.download_files(f\"/kaggle/input/building-prediction/{city}\")\n        self.logger.info(f\"{city}: Downloaded job results to data/{city}\")\n\n\n    def delete_jobs(self):\n        \"\"\"\n        Delete all jobs on the openEO backend. Use only for debugging. \n        \"\"\"\n        self.connect_to_openeo()\n\n        for idx, job in enumerate(self.openeo_connection.list_jobs()):\n            self.logger.info(f\"Deleting job {idx}, {job['id']}, {job['status']}\")\n            self.openeo_connection.job(job[\"id\"]).delete_job()\n\n\n    def create_and_start_openeo_job(self, city: str, collection_id: str = \"SENTINEL2_L2A\"):\n        \"\"\"\n        Creates an openeo processing job for a city and starts it.\n        \"\"\"\n        # Transform order in boundingbox to dict\n        boundingbox = self.get_boundingbox(city)\n        boundingbox = {\"west\": boundingbox[0], \"south\": boundingbox[1], \"east\": boundingbox[2], \"north\": boundingbox[3]}\n        \n        # Create datacube\n        datacube = self.openeo_connection.load_collection(\n            collection_id=collection_id,\n            spatial_extent=boundingbox,\n            temporal_extent=self.openeo_temporal_extent,\n            bands=self.openeo_bands,\n            max_cloud_cover=self.openeo_max_cloud_cover,\n        ).resample_spatial(self.openeo_spatial_resolution)\n\n        # Create cloud mask\n        scl = datacube.band(\"SCL\")\n\n        # Filter out cloud median probability, cloud high probability, and snow/ice\n        mask = (scl == 8) | (scl == 9) | (scl == 11)\n\n        # Resample mask to the spatial resolution of the datacube\n        mask = mask.resample_cube_spatial(datacube.band(\"B04\"))\n        \n        # Create the RGB image\n        datacube_rgbFU = datacube.filter_bands(self.openeo_bands[:-1])\n        \n        # Apply cloud mask\n        datacube_rgb_masked = datacube_rgbFU.mask(mask)\n        \n        # Reduce temporal to median \n        datacube_rgb_masked_reduced_t = datacube_rgb_masked.reduce_temporal(\"median\")\n\n        # Define image format \n        datacube_for_submission = datacube_rgb_masked_reduced_t.save_result(format=\"GTiff\")\n        \n        # Create openEO job with datacube\n        job = datacube_for_submission.create_job(title=f\"{city}__pic\")\n        self.logger.info(f\"{city}: Created openEO job\")\n\n        # Start openEO job\n        job.start_job()\n        self.logger.info(f\"{city}: Started openEO job with ID: {job.job_id}\")        \n\n        return job\n\n\n    def await_job(self, city, job):\n        \"\"\"\n        Awaits the processing of a openeo job. \n        Returns when the job is finished or raises an exception if the job failed.\n        \"\"\"\n\n        for i in range(30):\n            status = self.openeo_connection.job(job.job_id).status()\n            self.logger.debug(f\"{city}: Job {job.job_id} status: {status}\")\n          \n            if status == \"finished\":\n                self.logger.info(f\"{city}: Job {job.job_id} finished\")\n                return True\n            \n            elif status == \"error\":\n                self.logger.warning(f\"{city}: Job {job.job_id} failed. Trying again.\")\n                return False            \n            \n            time.sleep(60)\n        self.logger.error(f\"{city}: Job {job.job_id} did not finish in time\")\n        return False\n\n    def get_building_mask(self, city: str, loaded_buildings = None, all_touched: bool = False):  \n        \"\"\"\n        Get the local building mask for buildings in a city.\n        \"\"\"\n        if all_touched:\n            filename = \"building_mask_dense\"\n        else:\n            filename = \"building_mask_sparse\"\n        # Check if the building mask is already available\n        if os.path.exists(f\"/kaggle/input/building-prediction/{city}/{filename}.tif\"):\n            self.logger.info(f\"{city}: Using local building mask\")\n            return rasterio.open(f\"/kaggle/input/building-prediction/{city}/{filename}.tif\").read(1)\n\n        # Create new building mask \n        satellite_image = self.get_satellite_image(city, return_rasterio_dataset=True)\n\n        # Get satellite image metadata\n        transform = satellite_image.transform\n        out_shape = (satellite_image.height, satellite_image.width)\n        crs = satellite_image.crs\n\n        # Read the GeoJSON file with building polygons\n        if loaded_buildings is not None:\n            buildings = loaded_buildings\n        else:\n            buildings = self.get_buildings(city)\n            buildings = buildings.to_crs(crs)  # Ensure the CRS matches the GeoTIFF\n\n        # Create a mask where pixels inside buildings are True, others are False\n        # TODO all_touched paramer nutzen für zweite Maske\n        mask = geometry_mask(\n            buildings.geometry, transform=transform, invert=True, out_shape=out_shape, all_touched=all_touched,\n        )\n        \n        # Store the mask as a GeoTIFF file\n        \n        out_meta = satellite_image.meta\n        out_meta.update(\n            {\n                \"driver\": \"GTiff\",\n                \"height\": mask.shape[0],\n                \"width\": mask.shape[1],\n                # \"transform\": transform,\n                \"count\": 1,\n            }\n        )\n\n        # boolmask is automatically being saved as int16 [0,1]\n  \n        with rasterio.open(f\"/kaggle/input/building-prediction/{city}/{filename}.tif\", \"w\", **out_meta) as dest:\n            dest.write(mask, indexes=1)\n\n        return mask\n\nimport rasterio\nimport numpy as np\nimport torch\nfrom torch.utils.data import random_split, DataLoader, Dataset\nimport matplotlib.pyplot as plt\n\n\n\ndef create_tensor_of_windows(image, mask, patch_size=128):\n    \"\"\"\n    Create tensor with dimensions [N, H, W, C+1] from the satellite image of the city.\n    image should be of shape (H, W, C)\n    mask should be of shape (H, W, 1)\n    \"\"\"\n    # Merge Mask onto Image\n    image_with_mask = np.dstack((image, mask))\n\n    # cut of edges so image shape is divisible by patch size\n    reduced_image = image_with_mask[:-(image_with_mask.shape[0]%patch_size), :-(image_with_mask.shape[1]%patch_size)]\n\n\n    # calculate number of patches\n    N = reduced_image.shape[0]//patch_size*reduced_image.shape[1]//patch_size\n\n    # initialize target array\n    target_array = np.zeros((N, patch_size, patch_size, reduced_image.shape[-1]), dtype=np.uint16)\n\n    # fill target array\n    for row in range(patch_size):\n        for col in range(patch_size):\n            # calculate row and column indices\n            row_filter = range(row,reduced_image.shape[0]+row,patch_size)\n            col_filter = range(col,reduced_image.shape[1]+col,patch_size)\n\n            # write values into target array\n            target_array[:, row, col, :] = reduced_image[row_filter][:,col_filter,:].reshape(-1, reduced_image.shape[-1])\n\n    return target_array\n\n\n   \ndef divide_into_test_training(data, train_ratio=0.8):\n    \"\"\"\n    Divide the data into test and training split.\n    \"\"\"\n    \n    # Define the split ratio\n    test_ratio = 1 - train_ratio\n\n    # Calculate the sizes for training and test sets\n    train_size = int(train_ratio * len(data))\n    test_size = len(data) - train_size\n\n    # Split the dataset\n    train_dataset, test_dataset = random_split(data, [train_size, test_size])\n\n    return train_dataset, test_dataset\n\n\ndef create_data_loaders(train_dataset, test_dataset, batch_size = 64):\n    \"\"\"\n    Create DataLoaders.\n    \"\"\"\n    # Create DataLoaders\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n    return train_loader, test_loader\n\n\ndef apply_preprocessing_pipeline(images, masks, patch_size = 128, train_ratio = 0.8, batch_size = 64):\n    \"\"\"\n    applies windowing, deviding into train and test and creating data loaders.\n    \"\"\"\n\n    # for each city create patched images\n    patched_images = []\n    for image, mask in zip(images, masks):\n        patched_images.append(create_tensor_of_windows(image, mask, patch_size=patch_size))\n\n    # concatenate all patched images\n    patched_images_merged = np.concatenate(patched_images, axis=0)\n\n    # reorder axis to [N, C, H, W] for torch\n    patched_images_merged = np.transpose(patched_images_merged, (0,3,1,2))\n\n    # devide into train and test\n    train_ds, test_ds = divide_into_test_training(patched_images_merged,train_ratio=train_ratio)\n\n    # create data loaders\n    train_loader, test_loader = create_data_loaders(train_ds, test_ds, batch_size=batch_size)\n\n    return train_loader, test_loader\n\ndef plot_sub_image( image_data):\n    \"\"\"\n    Plot sub image.\n    \"\"\"\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n\n    ax[0].imshow(stretch_hist(image_data[:,:,:3]))\n    ax[1].imshow(stretch_hist(image_data[:,:,-1]))\n    return fig\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:03:24.051156Z","iopub.execute_input":"2024-06-28T12:03:24.051586Z","iopub.status.idle":"2024-06-28T12:03:31.354884Z","shell.execute_reply.started":"2024-06-28T12:03:24.051550Z","shell.execute_reply":"2024-06-28T12:03:31.354005Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install openeo pyrosm","metadata":{"execution":{"iopub.status.busy":"2024-06-28T11:54:09.441608Z","iopub.execute_input":"2024-06-28T11:54:09.441974Z","iopub.status.idle":"2024-06-28T12:00:09.778626Z","shell.execute_reply.started":"2024-06-28T11:54:09.441944Z","shell.execute_reply":"2024-06-28T12:00:09.777648Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting openeo\n  Downloading openeo-0.30.0-py3-none-any.whl.metadata (7.3 kB)\nCollecting pyrosm\n  Downloading pyrosm-0.6.2.tar.gz (2.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from openeo) (2.32.3)\nRequirement already satisfied: shapely>=1.6.4 in /opt/conda/lib/python3.10/site-packages (from openeo) (1.8.5.post1)\nRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from openeo) (1.26.4)\nRequirement already satisfied: xarray>=0.12.3 in /opt/conda/lib/python3.10/site-packages (from openeo) (2024.5.0)\nRequirement already satisfied: pandas>0.20.0 in /opt/conda/lib/python3.10/site-packages (from openeo) (2.2.1)\nCollecting pystac>=1.5.0 (from openeo)\n  Downloading pystac-1.10.1-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: deprecated>=1.2.12 in /opt/conda/lib/python3.10/site-packages (from openeo) (1.2.14)\nCollecting python-rapidjson (from pyrosm)\n  Downloading python_rapidjson-1.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\nRequirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.10/site-packages (from pyrosm) (69.0.3)\nRequirement already satisfied: geopandas>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from pyrosm) (0.14.4)\nCollecting shapely>=1.6.4 (from openeo)\n  Downloading shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting cykhash (from pyrosm)\n  Downloading cykhash-2.0.1.tar.gz (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting pyrobuf (from pyrosm)\n  Using cached pyrobuf-0.9.3-cp310-cp310-linux_x86_64.whl\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.12->openeo) (1.14.1)\nRequirement already satisfied: fiona>=1.8.21 in /opt/conda/lib/python3.10/site-packages (from geopandas>=0.12.0->pyrosm) (1.9.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from geopandas>=0.12.0->pyrosm) (21.3)\nRequirement already satisfied: pyproj>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from geopandas>=0.12.0->pyrosm) (3.6.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>0.20.0->openeo) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>0.20.0->openeo) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>0.20.0->openeo) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->openeo) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->openeo) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->openeo) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->openeo) (2024.2.2)\nCollecting packaging (from geopandas>=0.12.0->pyrosm)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: jinja2>=2.8 in /opt/conda/lib/python3.10/site-packages (from pyrobuf->pyrosm) (3.1.2)\nRequirement already satisfied: cython>=0.23 in /opt/conda/lib/python3.10/site-packages (from pyrobuf->pyrosm) (3.0.8)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (23.2.0)\nRequirement already satisfied: click~=8.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (8.1.7)\nRequirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (1.1.1)\nRequirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (0.7.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.12.0->pyrosm) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.8->pyrobuf->pyrosm) (2.1.3)\nDownloading openeo-0.30.0-py3-none-any.whl (260 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.2/260.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pystac-1.10.1-py3-none-any.whl (182 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.9/182.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading python_rapidjson-1.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pyrosm, cykhash\n  Building wheel for pyrosm (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyrosm: filename=pyrosm-0.6.2-cp310-cp310-linux_x86_64.whl size=2927743 sha256=949e6f624ed6541ae4a7adb40744343ccfa5fc0a19eea68ae57261a36685acb9\n  Stored in directory: /root/.cache/pip/wheels/18/21/22/b07b96a708420e351c553188667cfd6ebc7e78a011a8708cf4\n  Building wheel for cykhash (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cykhash: filename=cykhash-2.0.1-cp310-cp310-linux_x86_64.whl size=786067 sha256=8c862b2daab5f93466cf1ecb99f5868af0dfea501b028663359aca613888d790\n  Stored in directory: /root/.cache/pip/wheels/ed/de/7a/4386df8e70276a0d2ec5e990db76b6c89889dc41cd627e1c14\nSuccessfully built pyrosm cykhash\nInstalling collected packages: cykhash, shapely, python-rapidjson, packaging, pystac, pyrobuf, pyrosm, openeo\n  Attempting uninstall: shapely\n    Found existing installation: Shapely 1.8.5.post1\n    Uninstalling Shapely-1.8.5.post1:\n      Successfully uninstalled Shapely-1.8.5.post1\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\nkeras-nlp 0.12.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cykhash-2.0.1 openeo-0.30.0 packaging-24.1 pyrobuf-0.9.3 pyrosm-0.6.2 pystac-1.10.1 python-rapidjson-1.17 shapely-2.0.4\n","output_type":"stream"}]},{"cell_type":"code","source":"# basics\nimport numpy as np\nfrom tqdm.notebook import tqdm \n\n\n# torch\nimport torch\nfrom torch.utils.data import Dataset\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.tensorboard import SummaryWriter\n\n\n\n\n# Configure logging for the pipeline\nlogger = setup_logger(level='INFO')","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:04:01.550020Z","iopub.execute_input":"2024-06-28T12:04:01.550854Z","iopub.status.idle":"2024-06-28T12:04:14.926796Z","shell.execute_reply.started":"2024-06-28T12:04:01.550823Z","shell.execute_reply":"2024-06-28T12:04:14.925959Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-06-28 12:04:04.283577: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-28 12:04:04.283699: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-28 12:04:04.472173: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"cities = ['Aachen', 'CapeTown', 'Hamburg', 'Johannesburg', 'London', 'Montreal', 'Paris', 'Seoul', 'Singapore', 'Sydney']\n\ndatahandler = DataHandler(logger)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:04:15.906871Z","iopub.execute_input":"2024-06-28T12:04:15.907786Z","iopub.status.idle":"2024-06-28T12:04:15.913219Z","shell.execute_reply.started":"2024-06-28T12:04:15.907749Z","shell.execute_reply":"2024-06-28T12:04:15.912385Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2024-06-28 12:04:15,909 - root - INFO - __init__ - Data directory already exists\n","output_type":"stream"}]},{"cell_type":"code","source":"# load images and mask for all specified cites\n\nimport os\nimages = []\nsparse_masks=[]\ndense_masks=[]\n\nfor city in tqdm(cities):\n    buildings = None\n    images.append(datahandler.get_satellite_image(city))\n    sparse_masks.append(datahandler.get_building_mask(city, all_touched=False, loaded_buildings=buildings))\n    dense_masks.append(datahandler.get_building_mask(city, all_touched=True, loaded_buildings=buildings))","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:04:35.990512Z","iopub.execute_input":"2024-06-28T12:04:35.990951Z","iopub.status.idle":"2024-06-28T12:05:09.799733Z","shell.execute_reply.started":"2024-06-28T12:04:35.990918Z","shell.execute_reply":"2024-06-28T12:05:09.798767Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"120ac29cfc2446f5bc9af7d5c99bd812"}},"metadata":{}},{"name":"stderr","text":"2024-06-28 12:04:36,008 - root - INFO - get_satellite_image - Aachen: Using local satellite image\n2024-06-28 12:04:36,103 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Aachen/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n2024-06-28 12:04:36,919 - root - INFO - get_building_mask - Aachen: Using local building mask\n2024-06-28 12:04:37,001 - root - INFO - get_building_mask - Aachen: Using local building mask\n2024-06-28 12:04:37,092 - root - INFO - get_satellite_image - CapeTown: Using local satellite image\n2024-06-28 12:04:37,097 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/CapeTown/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n2024-06-28 12:04:39,440 - root - INFO - get_building_mask - CapeTown: Using local building mask\n2024-06-28 12:04:39,704 - root - INFO - get_building_mask - CapeTown: Using local building mask\n2024-06-28 12:04:40,020 - root - INFO - get_satellite_image - Hamburg: Using local satellite image\n2024-06-28 12:04:40,025 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Hamburg/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n2024-06-28 12:04:42,234 - root - INFO - get_building_mask - Hamburg: Using local building mask\n2024-06-28 12:04:42,487 - root - INFO - get_building_mask - Hamburg: Using local building mask\n2024-06-28 12:04:42,754 - root - INFO - get_satellite_image - Johannesburg: Using local satellite image\n2024-06-28 12:04:42,758 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Johannesburg/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n2024-06-28 12:04:48,917 - root - INFO - get_building_mask - Johannesburg: Using local building mask\n2024-06-28 12:04:49,587 - root - INFO - get_building_mask - Johannesburg: Using local building mask\n2024-06-28 12:04:50,176 - root - INFO - get_satellite_image - London: Using local satellite image\n2024-06-28 12:04:50,183 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/London/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n2024-06-28 12:04:55,348 - root - INFO - get_building_mask - London: Using local building mask\n2024-06-28 12:04:55,945 - root - INFO - get_building_mask - London: Using local building mask\n2024-06-28 12:04:56,225 - root - INFO - get_satellite_image - Montreal: Using local satellite image\n2024-06-28 12:04:56,229 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Montreal/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n2024-06-28 12:05:00,636 - root - INFO - get_building_mask - Montreal: Using local building mask\n2024-06-28 12:05:00,895 - root - INFO - get_building_mask - Montreal: Using local building mask\n2024-06-28 12:05:01,157 - root - INFO - get_satellite_image - Paris: Using local satellite image\n2024-06-28 12:05:01,162 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Paris/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n2024-06-28 12:05:01,425 - root - INFO - get_building_mask - Paris: Using local building mask\n2024-06-28 12:05:01,444 - root - INFO - get_building_mask - Paris: Using local building mask\n2024-06-28 12:05:01,465 - root - INFO - get_satellite_image - Seoul: Using local satellite image\n2024-06-28 12:05:01,469 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Seoul/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n2024-06-28 12:05:05,306 - root - INFO - get_building_mask - Seoul: Using local building mask\n2024-06-28 12:05:05,528 - root - INFO - get_building_mask - Seoul: Using local building mask\n2024-06-28 12:05:05,740 - root - INFO - get_satellite_image - Singapore: Using local satellite image\n2024-06-28 12:05:05,745 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Singapore/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n2024-06-28 12:05:07,048 - root - INFO - get_building_mask - Singapore: Using local building mask\n2024-06-28 12:05:07,120 - root - INFO - get_building_mask - Singapore: Using local building mask\n2024-06-28 12:05:07,194 - root - INFO - get_satellite_image - Sydney: Using local satellite image\n2024-06-28 12:05:07,198 - rasterio._env - WARNING - open - CPLE_AppDefined in /kaggle/input/building-prediction/Sydney/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWarning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n2024-06-28 12:05:09,535 - root - INFO - get_building_mask - Sydney: Using local building mask\n2024-06-28 12:05:09,668 - root - INFO - get_building_mask - Sydney: Using local building mask\n","output_type":"stream"}]},{"cell_type":"code","source":"# apply training pipeline\n# TODO make train test split consistent so we can train with multiple sizes, dont know if there is an advantage though\ntrain_loader, test_loader = apply_preprocessing_pipeline(images, sparse_masks, patch_size = 128, train_ratio = 0.8, batch_size = 64)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:06:29.669306Z","iopub.execute_input":"2024-06-28T12:06:29.669768Z","iopub.status.idle":"2024-06-28T12:07:22.766365Z","shell.execute_reply.started":"2024-06-28T12:06:29.669728Z","shell.execute_reply":"2024-06-28T12:07:22.765109Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"patch_size = 128\ntrain_ratio = 0.8\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:08:14.614977Z","iopub.execute_input":"2024-06-28T12:08:14.615975Z","iopub.status.idle":"2024-06-28T12:08:14.620195Z","shell.execute_reply.started":"2024-06-28T12:08:14.615938Z","shell.execute_reply":"2024-06-28T12:08:14.619310Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"patched_images = []\nmasks = sparse_masks\nfor image, mask in tqdm(zip(images, masks)):\n    patched_images.append(create_tensor_of_windows(image, mask, patch_size=patch_size))\n\n# concatenate all patched images\npatched_images_merged = np.concatenate(patched_images, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:09:08.240086Z","iopub.execute_input":"2024-06-28T12:09:08.240527Z","iopub.status.idle":"2024-06-28T12:10:00.454518Z","shell.execute_reply.started":"2024-06-28T12:09:08.240483Z","shell.execute_reply":"2024-06-28T12:10:00.453470Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cedb8e20d504209a3f6515809ac6b25"}},"metadata":{}}]},{"cell_type":"code","source":" patched_images_merged_reduced = patched_images_merged[~(patched_images_merged[...,-1].sum(axis=1).sum(axis=1)<1)]","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:15:12.437430Z","iopub.execute_input":"2024-06-28T12:15:12.438345Z","iopub.status.idle":"2024-06-28T12:15:13.123513Z","shell.execute_reply.started":"2024-06-28T12:15:12.438311Z","shell.execute_reply":"2024-06-28T12:15:13.122558Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# reorder axis to [N, C, H, W] for torch\npatched_images_merged_reduced = np.transpose(patched_images_merged_reduced, (0,3,1,2))\n\n# devide into train and test\ntrain_ds, test_ds = divide_into_test_training(patched_images_merged_reduced,train_ratio=train_ratio)\n\n# create data loaders\ntrain_loader, test_loader = create_data_loaders(train_ds, test_ds, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:15:13.845565Z","iopub.execute_input":"2024-06-28T12:15:13.845951Z","iopub.status.idle":"2024-06-28T12:15:13.852378Z","shell.execute_reply.started":"2024-06-28T12:15:13.845922Z","shell.execute_reply":"2024-06-28T12:15:13.851174Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# initialize model, taken from exercise pdf\nmodel = nn.Sequential(\n    nn.Conv2d(6, 32, kernel_size=3, padding=1), nn.ReLU(),\n    nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),\n    nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),\n    nn.Conv2d(128, 1, kernel_size=1, padding=0),\n    nn.Sigmoid())\n\n# initialize tensorboard writer\nwriter = SummaryWriter()","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:15:15.863452Z","iopub.execute_input":"2024-06-28T12:15:15.864162Z","iopub.status.idle":"2024-06-28T12:15:15.895503Z","shell.execute_reply.started":"2024-06-28T12:15:15.864131Z","shell.execute_reply":"2024-06-28T12:15:15.894764Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:15:53.088556Z","iopub.execute_input":"2024-06-28T12:15:53.088963Z","iopub.status.idle":"2024-06-28T12:15:53.137639Z","shell.execute_reply.started":"2024-06-28T12:15:53.088929Z","shell.execute_reply":"2024-06-28T12:15:53.136546Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'to'"],"ename":"AttributeError","evalue":"'DataLoader' object has no attribute 'to'","output_type":"error"}]},{"cell_type":"code","source":"# Instantiate the model, loss function, and optimizer\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\n# Training loop\nnum_epochs = 50\n\nmodel.train()\nfor epoch in tqdm(range(num_epochs)):\n    for batch in train_loader:\n        # splid in inputs and labels\n        inputs = batch[:,:-1].to(torch.float32)\n        labels = batch[:,-1, np.newaxis].to(torch.float32)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward pass\n        outputs = model(inputs)\n\n        # calculate loss\n        loss = criterion(outputs, labels)\n\n        # write to tensorboard\n        writer.add_scalar(\"Loss/train\", loss, epoch)\n\n        # backward pass\n        loss.backward()\n\n        # optimizer step\n        optimizer.step()\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T12:15:17.735158Z","iopub.execute_input":"2024-06-28T12:15:17.736016Z","iopub.status.idle":"2024-06-28T12:15:19.304856Z","shell.execute_reply.started":"2024-06-28T12:15:17.735980Z","shell.execute_reply":"2024-06-28T12:15:19.303607Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4bd8a618a084cd7b43fb787dd2140b6"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# splid in inputs and labels\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m batch[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     13\u001b[0m         labels \u001b[38;5;241m=\u001b[39m batch[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:171\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([torch\u001b[38;5;241m.\u001b[39mas_tensor(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:171\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m collate([\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map)\n","\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.uint16. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."],"ename":"TypeError","evalue":"can't convert np.ndarray of type numpy.uint16. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.","output_type":"error"}]},{"cell_type":"markdown","source":"## Save Model","metadata":{}},{"cell_type":"code","source":"import os\n\nos.makedirs(\"saved_models\", exist_ok=True)\ntorch.save(model.state_dict(), \"saved_models/model1\")","metadata":{},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"t  = torch.Tensor(test_loader.dataset)\n\n# splid in inputs and labels\ntest_inputs = t[:,:-1]#.to(torch.float32)\ntest_labels = t[:,-1, np.newaxis]#.to(torch.float32)\n\ntest_results = model(test_inputs).detach()\n\n# see how many percnet where predicted right\nthreshold = 0.5\n((test_results>threshold)==test_labels).sum()/np.prod(test_labels.shape)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import RocCurveDisplay\n\nRocCurveDisplay.from_predictions(\n   test_labels.flatten(), test_results.flatten())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"writer.flush()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download","metadata":{}},{"cell_type":"code","source":"\n\nbuildings = []\nsat_images = []\nbuilding_masks = []\n\nfor city in cities: \n    buildings.append(datahandler.get_buildings(city))\n    sat_images.append(datahandler.get_satellite_image(city))\n    building_masks.append(datahandler.get_building_mask(city))\n\n# Plot the expected results for the first city \ndatahandler.plot(city[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import data_preparation\n\nfor city in cities:\n    data_preparation.create_tensor(city)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download","metadata":{}},{"cell_type":"code","source":"# Download \n\nfor city in cities: \n    sat_image = datahandler.get_satellite_image(city)\n    mask = datahandler.get_building_mask(city)\n\n# Plot the expected results for the first city \ndatahandler.plot(city[0])","metadata":{},"execution_count":null,"outputs":[]}]}