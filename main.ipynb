{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import os\n",
    "import utils\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "\n",
    "\n",
    "# custom modules\n",
    "from data_acquisition import DataHandler\n",
    "from data_preparation import apply_preprocessing_pipeline\n",
    "\n",
    "\n",
    "# Configure logging for the pipeline\n",
    "logger = utils.setup_logger(level='INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 18:55:06,849 - root - INFO - __init__ - Data directory already exists\n",
      "2024-07-07 18:55:06,849 - root - INFO - __init__ - Data directory already exists\n"
     ]
    }
   ],
   "source": [
    "cities = [\"Wien\", 'London', 'CapeTown', 'Hamburg', 'Johannesburg', 'London', 'Montreal', 'Paris', 'Seoul', 'Singapore', 'Sydney']\n",
    "\n",
    "\n",
    "cities = [\n",
    "    \"Wien\",\n",
    "    \"Muenchen\",\n",
    "    # \"Soul\",\n",
    "    # \"CapeTown\",\n",
    "    # \"Paris\",\n",
    "    # \"Singapore\",\n",
    "    # \"Sidney\",\n",
    "    # \"London\",\n",
    "    # \"Montreal\",\n",
    "    # \"Bogota\"\n",
    "]\n",
    "\n",
    "test_city = [\"Berlin\"]\n",
    "\n",
    "datahandler = DataHandler(logger, path_to_data_directory=\"data\")\n",
    "datahandler.openeo_temporal_extent=[\"2023-01-01\", \"2023-12-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 18:55:08,787 - openeo.rest.connection - INFO - _get_oidc_provider - Found OIDC providers: ['CDSE']\n",
      "2024-07-07 18:55:08,787 - openeo.rest.connection - INFO - _get_oidc_provider - Found OIDC providers: ['CDSE']\n",
      "2024-07-07 18:55:08,789 - openeo.rest.connection - INFO - _get_oidc_provider - No OIDC provider given, but only one available: 'CDSE'. Using that one.\n",
      "2024-07-07 18:55:08,789 - openeo.rest.connection - INFO - _get_oidc_provider - No OIDC provider given, but only one available: 'CDSE'. Using that one.\n",
      "2024-07-07 18:55:09,169 - openeo.rest.connection - INFO - _get_oidc_provider_and_client_info - Using default client_id 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e' from OIDC provider 'CDSE' info.\n",
      "2024-07-07 18:55:09,169 - openeo.rest.connection - INFO - _get_oidc_provider_and_client_info - Using default client_id 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e' from OIDC provider 'CDSE' info.\n",
      "2024-07-07 18:55:09,174 - openeo.rest.connection - INFO - authenticate_oidc - Found refresh token: trying refresh token based authentication.\n",
      "2024-07-07 18:55:09,174 - openeo.rest.connection - INFO - authenticate_oidc - Found refresh token: trying refresh token based authentication.\n",
      "2024-07-07 18:55:09,176 - openeo.rest.auth.oidc - INFO - _do_token_post_request - Doing 'refresh_token' token request 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' with post data fields ['grant_type', 'client_id', 'refresh_token'] (client_id 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e')\n",
      "2024-07-07 18:55:09,176 - openeo.rest.auth.oidc - INFO - _do_token_post_request - Doing 'refresh_token' token request 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' with post data fields ['grant_type', 'client_id', 'refresh_token'] (client_id 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e')\n",
      "2024-07-07 18:55:09,482 - openeo.rest.connection - INFO - _authenticate_oidc - Obtained tokens: ['access_token', 'id_token', 'refresh_token']\n",
      "2024-07-07 18:55:09,482 - openeo.rest.connection - INFO - _authenticate_oidc - Obtained tokens: ['access_token', 'id_token', 'refresh_token']\n",
      "2024-07-07 18:55:09,484 - openeo.rest.auth.config - INFO - set_refresh_token - Storing refresh token for issuer 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE' (client 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e')\n",
      "2024-07-07 18:55:09,484 - openeo.rest.auth.config - INFO - set_refresh_token - Storing refresh token for issuer 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE' (client 'sh-b1c3a958-52d4-40fe-a333-153595d1c71e')\n",
      "2024-07-07 18:55:09,487 - root - INFO - connect_to_openeo - Connected to openEO\n",
      "2024-07-07 18:55:09,487 - root - INFO - connect_to_openeo - Connected to openEO\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 18:55:10,544 - root - INFO - delete_jobs - Deleting job 0, j-240707e059164effba02fcf339c87b8e, finished\n",
      "2024-07-07 18:55:10,544 - root - INFO - delete_jobs - Deleting job 0, j-240707e059164effba02fcf339c87b8e, finished\n"
     ]
    }
   ],
   "source": [
    "datahandler.delete_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07270568e1849ce879322bda7a777d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 18:55:19,990 - root - INFO - get_satellite_image - Wien: Using local satellite image\n",
      "2024-07-07 18:55:19,990 - root - INFO - get_satellite_image - Wien: Using local satellite image\n",
      "2024-07-07 18:55:20,002 - rasterio._env - WARNING - open - CPLE_AppDefined in data/Wien/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2024-07-07 18:55:20,002 - rasterio._env - WARNING - open - CPLE_AppDefined in data/Wien/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "Warning 1: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2024-07-07 18:55:20,787 - root - INFO - get_building_mask - Wien: Using local building mask\n",
      "2024-07-07 18:55:20,787 - root - INFO - get_building_mask - Wien: Using local building mask\n",
      "2024-07-07 18:55:20,814 - root - INFO - get_satellite_image - Wien: Using local satellite image\n",
      "2024-07-07 18:55:20,814 - root - INFO - get_satellite_image - Wien: Using local satellite image\n",
      "2024-07-07 18:55:20,817 - rasterio._env - WARNING - open - CPLE_AppDefined in data/Wien/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2024-07-07 18:55:20,817 - rasterio._env - WARNING - open - CPLE_AppDefined in data/Wien/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2024-07-07 18:55:20,819 - root - INFO - create_directory - Wien: Directory available\n",
      "2024-07-07 18:55:20,819 - root - INFO - create_directory - Wien: Directory available\n",
      "2024-07-07 18:55:20,821 - root - INFO - get_buildings - Wien: Using local building data\n",
      "2024-07-07 18:55:20,821 - root - INFO - get_buildings - Wien: Using local building data\n",
      "2024-07-07 18:56:05,722 - root - INFO - get_building_mask - Wien: Using local boundaries mask\n",
      "2024-07-07 18:56:05,722 - root - INFO - get_building_mask - Wien: Using local boundaries mask\n",
      "2024-07-07 18:56:05,845 - root - INFO - get_building_mask - Wien: Using local building mask\n",
      "2024-07-07 18:56:05,845 - root - INFO - get_building_mask - Wien: Using local building mask\n",
      "2024-07-07 18:56:05,892 - root - INFO - get_satellite_image - Wien: Using local satellite image\n",
      "2024-07-07 18:56:05,892 - root - INFO - get_satellite_image - Wien: Using local satellite image\n",
      "2024-07-07 18:56:05,895 - rasterio._env - WARNING - open - CPLE_AppDefined in data/Wien/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2024-07-07 18:56:05,895 - rasterio._env - WARNING - open - CPLE_AppDefined in data/Wien/openEO.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2024-07-07 18:56:05,898 - root - INFO - create_directory - Wien: Directory available\n",
      "2024-07-07 18:56:05,898 - root - INFO - create_directory - Wien: Directory available\n",
      "2024-07-07 18:56:05,900 - root - INFO - get_buildings - Wien: Using local building data\n",
      "2024-07-07 18:56:05,900 - root - INFO - get_buildings - Wien: Using local building data\n",
      "2024-07-07 18:56:42,449 - root - INFO - get_building_mask - Wien: Using local boundaries mask\n",
      "2024-07-07 18:56:42,449 - root - INFO - get_building_mask - Wien: Using local boundaries mask\n",
      "2024-07-07 18:56:42,581 - root - INFO - create_directory - Muenchen: Directory available\n",
      "2024-07-07 18:56:42,581 - root - INFO - create_directory - Muenchen: Directory available\n",
      "2024-07-07 18:56:42,587 - root - INFO - get_buildings - Muenchen: Using local building data\n",
      "2024-07-07 18:56:42,587 - root - INFO - get_buildings - Muenchen: Using local building data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading local buildings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 18:57:22,799 - root - INFO - connect_to_openeo - Already connected to openEO\n",
      "2024-07-07 18:57:22,799 - root - INFO - connect_to_openeo - Already connected to openEO\n",
      "2024-07-07 18:57:22,803 - root - INFO - download_satellite_image - Current jobs:\n",
      "2024-07-07 18:57:22,803 - root - INFO - download_satellite_image - Current jobs:\n",
      "2024-07-07 18:57:27,720 - root - INFO - create_and_start_openeo_job - Muenchen: Created openEO job\n",
      "2024-07-07 18:57:27,720 - root - INFO - create_and_start_openeo_job - Muenchen: Created openEO job\n",
      "2024-07-07 18:57:50,057 - root - INFO - create_and_start_openeo_job - Muenchen: Started openEO job with ID: j-240707953fde45668e2f08b6e57b3061\n",
      "2024-07-07 18:57:50,057 - root - INFO - create_and_start_openeo_job - Muenchen: Started openEO job with ID: j-240707953fde45668e2f08b6e57b3061\n"
     ]
    }
   ],
   "source": [
    "# load images and mask for all specified cites\n",
    "\n",
    "import os\n",
    "images = []\n",
    "sparse_masks=[]\n",
    "dense_masks=[]\n",
    "\n",
    "for city in tqdm(cities):\n",
    "    buildings = None\n",
    "    if not os.path.exists(os.path.join(datahandler.path_to_data_directory,city,'building_mask_dense.tif')):\n",
    "        print(\"loading local buildings\")\n",
    "        buildings = datahandler.get_buildings(city)\n",
    "    images.append(datahandler.get_satellite_image(city))\n",
    "    sparse_masks.append(datahandler.get_building_mask(city, all_touched=False, loaded_buildings=buildings))\n",
    "    dense_masks.append(datahandler.get_building_mask(city, all_touched=True, loaded_buildings=buildings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = sparse_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Differences of train and test set is below 10% on mean, std, min and max across all input bands\n",
      "!!!There might be large diffferecenes between train and validation set. Please choose another seed for splitting. For more detail see the differences below\n",
      "       std\n",
      "R  0.13538\n",
      "\n",
      "Comparison of distribution of masks:\n",
      "                   mean  median          std  10th percentile  90th percentile\n",
      "Train       877.862372   324.5  1186.567560             15.0           2599.0\n",
      "Test        815.344802   308.0  1126.038312             16.0           2411.5\n",
      "Validation  914.068864   413.0  1201.558744             18.0           2483.2\n",
      "\n",
      "Index([0.0, 1.0, 2.0, 3.0, 4.0], dtype='float64')\n",
      "Comparison of cities the data in the differen sets originates from:\n",
      "               London  CapeTown   Hamburg  Johannesburg    London\n",
      "Train       0.283065  0.090288  0.131772      0.206930  0.287945\n",
      "Test        0.285505  0.079795  0.125915      0.207174  0.301611\n",
      "Validation  0.310623  0.095238  0.131868      0.182418  0.279853\n"
     ]
    }
   ],
   "source": [
    "# apply training pipeline\n",
    "# TODO make train test split consistent so we can train with multiple sizes, dont know if there is an advantage though\n",
    "train_loader, test_loader , validation_loader = apply_preprocessing_pipeline(\n",
    "    images, \n",
    "    masks, \n",
    "    patch_size = 128, \n",
    "    test_ratio= 0.2,\n",
    "    validation_ratio=0.2, \n",
    "    batch_size = 64, \n",
    "    show_validation_of_split=True,\n",
    "    city_names=cities, \n",
    "    minimum_number_of_true_pixels_per_image=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 7, 128, 128]), torch.Tensor, torch.uint16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train_loader))   \n",
    "sample.shape, type(sample), sample.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class convNetSimple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "                nn.Conv2d(6, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
    "                nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
    "                nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),\n",
    "                nn.Conv2d(128, 1, kernel_size=1, padding=0),\n",
    "                nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class LitNet(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch[:,:-1], batch[:,-1]\n",
    "        outs = self.model(x.float())\n",
    "        loss = self.loss(outs, y.unsqueeze(1).float())\n",
    "        self.log(\"train_loss\", value=loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch[:,:-1], batch[:,-1]\n",
    "        outs = self.model(x.float())\n",
    "        loss = self.loss(outs, y.unsqueeze(1).float())\n",
    "        values = {\"val_loss\": loss}\n",
    "        self.log_dict(values, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "        \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch[:,:-1], batch[:,-1]\n",
    "        outs = self.model(x.float())\n",
    "        loss = self.loss(outs, y.unsqueeze(1).float())\n",
    "        \n",
    "        values = {\n",
    "            \"test_loss\": loss,\n",
    "        }\n",
    "        self.log_dict(values, on_epoch=True, on_step=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load trained model\n",
    "convmodel = LitNet(convNetSimple())\n",
    "model_dict = torch.load(\"models/lightning_logs/version_1/checkpoints/epoch=39-step=7000.ckpt\", map_location=torch.device('cpu'))\n",
    "convmodel.load_state_dict(model_dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 42\n",
      "2024-06-28 23:29:49,796 - lightning.fabric.utilities.seed - INFO - seed_everything - Seed set to 42\n",
      "2024-06-28 23:29:49,796 - lightning.fabric.utilities.seed - INFO - seed_everything - Seed set to 42\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "2024-06-28 23:29:49,816 - lightning.pytorch.utilities.rank_zero - INFO - _info - GPU available: True (cuda), used: True\n",
      "2024-06-28 23:29:49,816 - lightning.pytorch.utilities.rank_zero - INFO - _info - GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "2024-06-28 23:29:49,818 - lightning.pytorch.utilities.rank_zero - INFO - _info - TPU available: False, using: 0 TPU cores\n",
      "2024-06-28 23:29:49,818 - lightning.pytorch.utilities.rank_zero - INFO - _info - TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "2024-06-28 23:29:49,819 - lightning.pytorch.utilities.rank_zero - INFO - _info - HPU available: False, using: 0 HPUs\n",
      "2024-06-28 23:29:49,819 - lightning.pytorch.utilities.rank_zero - INFO - _info - HPU available: False, using: 0 HPUs\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2024-06-28 23:29:49,823 - lightning.pytorch.accelerators.cuda - INFO - set_nvidia_flags - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2024-06-28 23:29:49,823 - lightning.pytorch.accelerators.cuda - INFO - set_nvidia_flags - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name  | Type          | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | model | convNetSimple | 94.2 K | train\n",
      "1 | loss  | BCELoss       | 0      | train\n",
      "------------------------------------------------\n",
      "94.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "94.2 K    Total params\n",
      "0.377     Total estimated model params size (MB)\n",
      "2024-06-28 23:29:49,836 - lightning.pytorch.callbacks.model_summary - INFO - summarize - \n",
      "  | Name  | Type          | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | model | convNetSimple | 94.2 K | train\n",
      "1 | loss  | BCELoss       | 0      | train\n",
      "------------------------------------------------\n",
      "94.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "94.2 K    Total params\n",
      "0.377     Total estimated model params size (MB)\n",
      "2024-06-28 23:29:49,836 - lightning.pytorch.callbacks.model_summary - INFO - summarize - \n",
      "  | Name  | Type          | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | model | convNetSimple | 94.2 K | train\n",
      "1 | loss  | BCELoss       | 0      | train\n",
      "------------------------------------------------\n",
      "94.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "94.2 K    Total params\n",
      "0.377     Total estimated model params size (MB)\n",
      "/home/jlb/Dev/architecture-of-ml-systems/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=20` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a2bdef495f4e469644770c2113461d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=40` reached.\n",
      "2024-06-28 23:47:55,487 - lightning.pytorch.utilities.rank_zero - INFO - _info - `Trainer.fit` stopped: `max_epochs=40` reached.\n",
      "2024-06-28 23:47:55,487 - lightning.pytorch.utilities.rank_zero - INFO - _info - `Trainer.fit` stopped: `max_epochs=40` reached.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2024-06-28 23:47:55,519 - lightning.pytorch.accelerators.cuda - INFO - set_nvidia_flags - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2024-06-28 23:47:55,519 - lightning.pytorch.accelerators.cuda - INFO - set_nvidia_flags - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/jlb/Dev/architecture-of-ml-systems/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=20` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b6783770584ec982a5b3b9755c6e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_loss_epoch         9.542298316955566\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 9.542298316955566}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "\n",
    "L.seed_everything(42)\n",
    "convmodel = LitNet(convNetSimple())\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=\"models\",\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            patience=10,\n",
    "        )\n",
    "        ModelCheckpoint(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=2,\n",
    "            dirpath=\"models\",\n",
    "            filename=\"best_model\"\n",
    "        )\n",
    "    ]\n",
    "    val_check_interval=1,\n",
    "    fast_dev_run=False,\n",
    "    num_sanity_val_steps=2,\n",
    "    max_epochs=40,\n",
    "    log_every_n_steps=20,\n",
    ")\n",
    "\n",
    "# training\n",
    "trainer.fit(convmodel, \n",
    "    train_dataloaders=train_loader,\n",
    "    # val_dataloaders=val_loader   #### HIER brauchen wir noch einen validation loader\n",
    ")\n",
    "\n",
    "\n",
    "# testing\n",
    "\n",
    "# hier könnte man noch das beste model laden, wenn wir ein Val dataset haben.\n",
    "# best_model = LitModel.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "# trainer.test(\n",
    "#     best_model,\n",
    "#     dataloaders=test_loader\n",
    "# )\n",
    "\n",
    "\n",
    "trainer.test(\n",
    "    convmodel,\n",
    "    dataloaders=test_loader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model, loss function, and optimizer\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 50\n",
    "\n",
    "# model.train()\n",
    "# for epoch in tqdm(range(num_epochs)):\n",
    "#     for batch in train_loader:\n",
    "#         # splid in inputs and labels\n",
    "#         inputs = batch[:,:-1].to(torch.float32)\n",
    "#         labels = batch[:,-1, np.newaxis].to(torch.float32)\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward pass\n",
    "#         outputs = model(inputs)\n",
    "\n",
    "#         # calculate loss\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         # write to tensorboard\n",
    "#         writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "#         # backward pass\n",
    "#         loss.backward()\n",
    "\n",
    "#         # optimizer step\n",
    "#         optimizer.step()\n",
    "    \n",
    "# writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.makedirs(\"saved_models\", exist_ok=True)\n",
    "# torch.save(model.state_dict(), \"saved_models/model1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9638)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test set\n",
    "t  = torch.Tensor(test_loader.dataset)\n",
    "\n",
    "# splid in inputs and labels\n",
    "test_inputs = t[:,:-1]#.to(torch.float32)\n",
    "test_labels = t[:,-1, np.newaxis]#.to(torch.float32)\n",
    "\n",
    "test_results = convmodel(test_inputs).detach()\n",
    "\n",
    "# Look at sums, to check if model only predicts zeros\n",
    "print(\"Sum of test results: \", test_results.sum())\n",
    "print(\"But it should be closer to: \", test_labels.sum())\n",
    "\n",
    "\n",
    "# # see how many percnet where predicted right\n",
    "threshold = 0.5\n",
    "((test_results>threshold)==test_labels).sum()/np.prod(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# RocCurveDisplay.from_predictions(\n",
    "#    test_labels.flatten(), test_results.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t  = torch.Tensor(test_loader.dataset)\n",
    "\n",
    "# # splid in inputs and labels\n",
    "# test_inputs = t[:,:-1]#.to(torch.float32)\n",
    "# test_labels = t[:,-1, np.newaxis]#.to(torch.float32)\n",
    "\n",
    "# test_results = model(test_inputs).detach()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "buildings = []\n",
    "sat_images = []\n",
    "building_masks = []\n",
    "\n",
    "for city in cities: \n",
    "    buildings.append(datahandler.get_buildings(city))\n",
    "    sat_images.append(datahandler.get_satellite_image(city))\n",
    "    building_masks.append(datahandler.get_building_mask(city))\n",
    "\n",
    "# Plot the expected results for the first city \n",
    "datahandler.plot(city[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preparation\n",
    "\n",
    "for city in cities:\n",
    "    data_preparation.create_tensor(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download \n",
    "\n",
    "for city in cities: \n",
    "    sat_image = datahandler.get_satellite_image(city)\n",
    "    mask = datahandler.get_building_mask(city)\n",
    "\n",
    "# Plot the expected results for the first city \n",
    "datahandler.plot(city[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
