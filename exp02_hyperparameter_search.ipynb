{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_preperation.dataset import CityDataset\n",
    "import os\n",
    "\n",
    "from config import PATH, CITIES, MIN_LABELS, PATCH_SIZE, TEST_CITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CityDataset(\n",
    "    PATH,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    data_name=\"openEO.tif\",\n",
    "    labels_name=\"building_mask_dense.tif\",\n",
    "    image_bands=[1, 2, 3, 4, 5, 6],\n",
    "    min_labels=MIN_LABELS,\n",
    "    cities=CITIES,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "dataset_test = CityDataset(\n",
    "    PATH,\n",
    "    data_name=\"openEO.tif\",\n",
    "    labels_name=\"building_mask_dense.tif\",\n",
    "    image_bands=[1, 2, 3, 4, 5, 6],\n",
    "    cities=TEST_CITY,\n",
    "    train=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import lightning as L\n",
    "from typing import Any\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from lightning import seed_everything\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from models.lightning_utils import LitModule\n",
    "from models.baseconvnet import ConvNetSimple\n",
    "\n",
    "from lightning.pytorch.tuner.tuning import Tuner\n",
    "\n",
    "# model\n",
    "# convmodel = LitModule(ConvNetSimple())\n",
    "\n",
    "\n",
    "# trainer\n",
    "def get_trainer(dirname):\n",
    "    trainer = L.Trainer(\n",
    "        default_root_dir=f\"model_experiments/hyperparam_tuning/{dirname}\",\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"min\",\n",
    "                patience=2,\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                dirpath=f\"model_experiments/hyperparam_tuning/{dirname}\",\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"min\",\n",
    "                save_top_k=1,\n",
    "                filename=\"best_model\",\n",
    "            ),\n",
    "        ],\n",
    "        # val_check_interval=1,\n",
    "        fast_dev_run=False,\n",
    "        num_sanity_val_steps=2,\n",
    "        max_epochs=10,\n",
    "        log_every_n_steps=20,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import random\n",
    "\n",
    "b = {\"B04\": 1, \"B03\": 2, \"B02\": 3, \"B08\": 4, \"B12\": 5, \"B11\": 6}\n",
    "channels = list(b.values())\n",
    "print(channels)\n",
    "optimizers = [\"sgd\", \"adamW\", \"adam\"]\n",
    "\n",
    "grid = []\n",
    "i = 0\n",
    "while i < 5:\n",
    "    num_channels = random.randint(3, 6)\n",
    "    selected_channels = random.sample(channels, num_channels)\n",
    "    selected_channels.sort()\n",
    "    if selected_channels not in grid:\n",
    "        i += 1\n",
    "        grid.append(selected_channels)\n",
    "    else:\n",
    "        continue\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = {}\n",
    "torch.set_float32_matmul_precision(\"high\")  # for tensor cores\n",
    "test_dl = DataLoader(dataset_test, batch_size=32, shuffle=False, num_workers=20)\n",
    "for chs in grid:\n",
    "    print(chs)\n",
    "    # load the data\n",
    "    dataset = CityDataset(\n",
    "        PATH,\n",
    "        patch_size=32,\n",
    "        data_name=\"openEO.tif\",\n",
    "        labels_name=\"building_mask_dense.tif\",\n",
    "        image_bands=chs,\n",
    "        min_labels=0.1,\n",
    "        cities=CITIES,\n",
    "        train=True,\n",
    "    )\n",
    "    train_ds, val_ds = dataset.train_val_split(val_size=0.1, show_summary=False)\n",
    "    train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=20)\n",
    "    val_dl = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=20)\n",
    "\n",
    "    dataset_test = CityDataset(\n",
    "        PATH,\n",
    "        data_name=\"openEO.tif\",\n",
    "        labels_name=\"building_mask_dense.tif\",\n",
    "        image_bands=chs,\n",
    "        cities=TEST_CITY,\n",
    "        train=False,\n",
    "    )\n",
    "    test_dl = DataLoader(dataset_test, batch_size=32, shuffle=False, num_workers=20)\n",
    "\n",
    "    for optim in optimizers:\n",
    "        print(chs, optim)\n",
    "        # create the model\n",
    "        model = LitModule(ConvNetSimple(len(chs)), learning_rate=0.001, optimizer=optim)\n",
    "        # create the trainer\n",
    "        trainer = get_trainer(\n",
    "            f'convSimple/{str(chs).replace(\", \", \"_\").replace(\"[\", \"_\").replace(\"]\", \"_\")}{optim}'\n",
    "        )\n",
    "        # tuner lr\n",
    "        seed_everything(49)\n",
    "        tuner = Tuner(trainer=trainer)\n",
    "        tuner.lr_find(\n",
    "            model, train_dl, val_dl, min_lr=1e-5, max_lr=0.03, num_training=5000\n",
    "        )\n",
    "\n",
    "        # train the model\n",
    "        trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "        model_stats[f\"{str(chs)}_{optim}\"] = dict(\n",
    "            best_model=trainer.checkpoint_callback.best_model_path,\n",
    "        )\n",
    "        # test the model\n",
    "        best_model = LitModule.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path\n",
    "        )\n",
    "        trainer.test(model=model, dataloaders=test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET Hyperparam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats = {}\n",
    "from models.unet import UNet\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")  # for tensor cores\n",
    "test_dl = DataLoader(dataset_test, batch_size=32, shuffle=False, num_workers=20)\n",
    "for chs in grid:\n",
    "    print(chs)\n",
    "    # load the data\n",
    "    dataset = CityDataset(\n",
    "        PATH,\n",
    "        patch_size=32,\n",
    "        data_name=\"openEO.tif\",\n",
    "        labels_name=\"building_mask_dense.tif\",\n",
    "        image_bands=chs,\n",
    "        min_labels=0.1,\n",
    "        cities=CITIES,\n",
    "        train=True,\n",
    "    )\n",
    "    train_ds, val_ds = dataset.train_val_split(val_size=0.1, show_summary=False)\n",
    "    train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=20)\n",
    "    val_dl = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=20)\n",
    "\n",
    "    dataset_test = CityDataset(\n",
    "        PATH,\n",
    "        data_name=\"openEO.tif\",\n",
    "        labels_name=\"building_mask_dense.tif\",\n",
    "        image_bands=chs,\n",
    "        cities=TEST_CITY,\n",
    "        train=False,\n",
    "    )\n",
    "    test_dl = DataLoader(dataset_test, batch_size=32, shuffle=False, num_workers=20)\n",
    "\n",
    "    for optim in optimizers:\n",
    "        print(chs, optim)\n",
    "        # create the model\n",
    "\n",
    "        # model\n",
    "        unet = UNet(\n",
    "            n_channels=len(dataset.get_image_bands()), n_classes=1, bilinear=True\n",
    "        )\n",
    "        # UNet implementation uses the BCEWithLogitsLoss, lr of 1e-5 default\n",
    "        model = LitModule(unet, learning_rate=1e-4, loss=nn.BCEWithLogitsLoss())\n",
    "\n",
    "        # create the trainer\n",
    "        trainer = get_trainer(\n",
    "            f'unet/{str(chs).replace(\", \", \"_\").replace(\"[\", \"_\").replace(\"]\", \"_\")}{optim}'\n",
    "        )\n",
    "\n",
    "        # tuner lr\n",
    "        seed_everything(49)\n",
    "        tuner = Tuner(trainer=trainer)\n",
    "        tuner.lr_find(\n",
    "            model, train_dl, val_dl, min_lr=1e-5, max_lr=0.03, num_training=5000\n",
    "        )\n",
    "\n",
    "        # train the model\n",
    "        trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "        model_stats[f\"{str(chs)}_{optim}\"] = dict(\n",
    "            best_model=trainer.checkpoint_callback.best_model_path,\n",
    "        )\n",
    "        # test the model\n",
    "        best_model = LitModule.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path\n",
    "        )\n",
    "        trainer.test(model=model, dataloaders=test_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
